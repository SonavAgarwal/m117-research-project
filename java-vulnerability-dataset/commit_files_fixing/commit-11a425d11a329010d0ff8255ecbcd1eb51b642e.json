{
    "sha": "11a425d11a329010d0ff8255ecbcd1eb51b642e3",
    "node_id": "MDY6Q29tbWl0MjM0MTg1MTc6MTFhNDI1ZDExYTMyOTAxMGQwZmY4MjU1ZWNiY2QxZWI1MWI2NDJlMw==",
    "commit": {
        "author": {
            "name": "Kihwal Lee",
            "email": "kihwal@apache.org",
            "date": "2018-05-29T20:02:33Z"
        },
        "committer": {
            "name": "Kihwal Lee",
            "email": "kihwal@apache.org",
            "date": "2018-05-29T20:02:33Z"
        },
        "message": "Additional check when unpacking archives. Contributed by Wilfred Spiegelenburg.\n\n(cherry picked from commit e3236a9680709de7a95ffbc11b20e1bdc95a8605)",
        "tree": {
            "sha": "ae152d483edd7b6d3a6e6ac86d81de3da458ac07",
            "url": "https://api.github.com/repos/apache/hadoop/git/trees/ae152d483edd7b6d3a6e6ac86d81de3da458ac07"
        },
        "url": "https://api.github.com/repos/apache/hadoop/git/commits/11a425d11a329010d0ff8255ecbcd1eb51b642e3",
        "comment_count": 0,
        "verification": {
            "verified": false,
            "reason": "unsigned",
            "signature": null,
            "payload": null,
            "verified_at": null
        }
    },
    "url": "https://api.github.com/repos/apache/hadoop/commits/11a425d11a329010d0ff8255ecbcd1eb51b642e3",
    "html_url": "https://github.com/apache/hadoop/commit/11a425d11a329010d0ff8255ecbcd1eb51b642e3",
    "comments_url": "https://api.github.com/repos/apache/hadoop/commits/11a425d11a329010d0ff8255ecbcd1eb51b642e3/comments",
    "author": {
        "login": "kihwal",
        "id": 340000,
        "node_id": "MDQ6VXNlcjM0MDAwMA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/340000?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/kihwal",
        "html_url": "https://github.com/kihwal",
        "followers_url": "https://api.github.com/users/kihwal/followers",
        "following_url": "https://api.github.com/users/kihwal/following{/other_user}",
        "gists_url": "https://api.github.com/users/kihwal/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/kihwal/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/kihwal/subscriptions",
        "organizations_url": "https://api.github.com/users/kihwal/orgs",
        "repos_url": "https://api.github.com/users/kihwal/repos",
        "events_url": "https://api.github.com/users/kihwal/events{/privacy}",
        "received_events_url": "https://api.github.com/users/kihwal/received_events",
        "type": "User",
        "user_view_type": "public",
        "site_admin": false
    },
    "committer": {
        "login": "kihwal",
        "id": 340000,
        "node_id": "MDQ6VXNlcjM0MDAwMA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/340000?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/kihwal",
        "html_url": "https://github.com/kihwal",
        "followers_url": "https://api.github.com/users/kihwal/followers",
        "following_url": "https://api.github.com/users/kihwal/following{/other_user}",
        "gists_url": "https://api.github.com/users/kihwal/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/kihwal/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/kihwal/subscriptions",
        "organizations_url": "https://api.github.com/users/kihwal/orgs",
        "repos_url": "https://api.github.com/users/kihwal/repos",
        "events_url": "https://api.github.com/users/kihwal/events{/privacy}",
        "received_events_url": "https://api.github.com/users/kihwal/received_events",
        "type": "User",
        "user_view_type": "public",
        "site_admin": false
    },
    "parents": [
        {
            "sha": "a1fd04c4f472fdc0835f491a719220684ee1f255",
            "url": "https://api.github.com/repos/apache/hadoop/commits/a1fd04c4f472fdc0835f491a719220684ee1f255",
            "html_url": "https://github.com/apache/hadoop/commit/a1fd04c4f472fdc0835f491a719220684ee1f255"
        }
    ],
    "stats": {
        "total": 56,
        "additions": 55,
        "deletions": 1
    },
    "files": [
        {
            "sha": "239d46485a022436ba83dc588cdcf7b781395e0e",
            "filename": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/RunJar.java",
            "status": "modified",
            "additions": 10,
            "deletions": 0,
            "changes": 10,
            "blob_url": "https://github.com/apache/hadoop/blob/11a425d11a329010d0ff8255ecbcd1eb51b642e3/hadoop-common-project%2Fhadoop-common%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fhadoop%2Futil%2FRunJar.java",
            "raw_url": "https://github.com/apache/hadoop/raw/11a425d11a329010d0ff8255ecbcd1eb51b642e3/hadoop-common-project%2Fhadoop-common%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fhadoop%2Futil%2FRunJar.java",
            "contents_url": "https://api.github.com/repos/apache/hadoop/contents/hadoop-common-project%2Fhadoop-common%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fhadoop%2Futil%2FRunJar.java?ref=11a425d11a329010d0ff8255ecbcd1eb51b642e3",
            "patch": "@@ -113,12 +113,17 @@ public static void unJar(InputStream inputStream, File toDir,\n       throws IOException {\n     try (JarInputStream jar = new JarInputStream(inputStream)) {\n       int numOfFailedLastModifiedSet = 0;\n+      String targetDirPath = toDir.getCanonicalPath() + File.separator;\n       for (JarEntry entry = jar.getNextJarEntry();\n            entry != null;\n            entry = jar.getNextJarEntry()) {\n         if (!entry.isDirectory() &&\n             unpackRegex.matcher(entry.getName()).matches()) {\n           File file = new File(toDir, entry.getName());\n+          if (!file.getCanonicalPath().startsWith(targetDirPath)) {\n+            throw new IOException(\"expanding \" + entry.getName()\n+                + \" would create file outside of \" + toDir);\n+          }\n           ensureDirectory(file.getParentFile());\n           try (OutputStream out = new FileOutputStream(file)) {\n             IOUtils.copyBytes(jar, out, BUFFER_SIZE);\n@@ -178,13 +183,18 @@ public static void unJar(File jarFile, File toDir, Pattern unpackRegex)\n       throws IOException {\n     try (JarFile jar = new JarFile(jarFile)) {\n       int numOfFailedLastModifiedSet = 0;\n+      String targetDirPath = toDir.getCanonicalPath() + File.separator;\n       Enumeration<JarEntry> entries = jar.entries();\n       while (entries.hasMoreElements()) {\n         final JarEntry entry = entries.nextElement();\n         if (!entry.isDirectory() &&\n             unpackRegex.matcher(entry.getName()).matches()) {\n           try (InputStream in = jar.getInputStream(entry)) {\n             File file = new File(toDir, entry.getName());\n+            if (!file.getCanonicalPath().startsWith(targetDirPath)) {\n+              throw new IOException(\"expanding \" + entry.getName()\n+                  + \" would create file outside of \" + toDir);\n+            }\n             ensureDirectory(file.getParentFile());\n             try (OutputStream out = new FileOutputStream(file)) {\n               IOUtils.copyBytes(in, out, BUFFER_SIZE);"
        },
        {
            "sha": "237751c20ca912ccbe911b2b8912017d61a5d1b4",
            "filename": "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestRunJar.java",
            "status": "modified",
            "additions": 45,
            "deletions": 1,
            "changes": 46,
            "blob_url": "https://github.com/apache/hadoop/blob/11a425d11a329010d0ff8255ecbcd1eb51b642e3/hadoop-common-project%2Fhadoop-common%2Fsrc%2Ftest%2Fjava%2Forg%2Fapache%2Fhadoop%2Futil%2FTestRunJar.java",
            "raw_url": "https://github.com/apache/hadoop/raw/11a425d11a329010d0ff8255ecbcd1eb51b642e3/hadoop-common-project%2Fhadoop-common%2Fsrc%2Ftest%2Fjava%2Forg%2Fapache%2Fhadoop%2Futil%2FTestRunJar.java",
            "contents_url": "https://api.github.com/repos/apache/hadoop/contents/hadoop-common-project%2Fhadoop-common%2Fsrc%2Ftest%2Fjava%2Forg%2Fapache%2Fhadoop%2Futil%2FTestRunJar.java?ref=11a425d11a329010d0ff8255ecbcd1eb51b642e3",
            "patch": "@@ -17,9 +17,12 @@\n  */\n package org.apache.hadoop.util;\n \n+import static org.apache.hadoop.util.RunJar.MATCH_ANY;\n import static org.junit.Assert.assertEquals;\n import static org.junit.Assert.assertFalse;\n import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.fail;\n+import static org.mockito.Matchers.any;\n import static org.mockito.Mockito.spy;\n import static org.mockito.Mockito.when;\n \n@@ -28,6 +31,7 @@\n import java.io.FileOutputStream;\n import java.io.IOException;\n import java.io.InputStream;\n+import java.nio.charset.StandardCharsets;\n import java.util.Random;\n import java.util.jar.JarEntry;\n import java.util.jar.JarOutputStream;\n@@ -222,4 +226,44 @@ public void testClientClassLoader() throws Throwable {\n     runJar.run(args);\n     // it should not throw an exception\n   }\n-}\n\\ No newline at end of file\n+\n+  @Test\n+  public void testUnJar2() throws IOException {\n+    // make a simple zip\n+    File jarFile = new File(TEST_ROOT_DIR, TEST_JAR_NAME);\n+    JarOutputStream jstream =\n+        new JarOutputStream(new FileOutputStream(jarFile));\n+    JarEntry je = new JarEntry(\"META-INF/MANIFEST.MF\");\n+    byte[] data = \"Manifest-Version: 1.0\\nCreated-By: 1.8.0_1 (Manual)\"\n+        .getBytes(StandardCharsets.UTF_8);\n+    je.setSize(data.length);\n+    jstream.putNextEntry(je);\n+    jstream.write(data);\n+    jstream.closeEntry();\n+    je = new JarEntry(\"../outside.path\");\n+    data = \"any data here\".getBytes(StandardCharsets.UTF_8);\n+    je.setSize(data.length);\n+    jstream.putNextEntry(je);\n+    jstream.write(data);\n+    jstream.closeEntry();\n+    jstream.close();\n+\n+    File unjarDir = getUnjarDir(\"unjar-path\");\n+\n+    // Unjar everything\n+    try {\n+      RunJar.unJar(jarFile, unjarDir, MATCH_ANY);\n+      fail(\"unJar should throw IOException.\");\n+    } catch (IOException e) {\n+      GenericTestUtils.assertExceptionContains(\n+          \"would create file outside of\", e);\n+    }\n+    try {\n+      RunJar.unJar(new FileInputStream(jarFile), unjarDir, MATCH_ANY);\n+      fail(\"unJar should throw IOException.\");\n+    } catch (IOException e) {\n+      GenericTestUtils.assertExceptionContains(\n+          \"would create file outside of\", e);\n+    }\n+  }\n+}"
        }
    ]
}