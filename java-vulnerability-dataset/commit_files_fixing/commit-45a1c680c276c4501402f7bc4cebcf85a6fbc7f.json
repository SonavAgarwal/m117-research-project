{
    "sha": "45a1c680c276c4501402f7bc4cebcf85a6fbc7f5",
    "node_id": "MDY6Q29tbWl0MjM0MTg1MTc6NDVhMWM2ODBjMjc2YzQ1MDE0MDJmN2JjNGNlYmNmODVhNmZiYzdmNQ==",
    "commit": {
        "author": {
            "name": "Akira Ajisaka",
            "email": "aajisaka@apache.org",
            "date": "2018-05-23T08:21:46Z"
        },
        "committer": {
            "name": "Akira Ajisaka",
            "email": "aajisaka@apache.org",
            "date": "2018-05-23T08:21:46Z"
        },
        "message": "Additional check when unpacking archives. Contributed by Jason Lowe and Akira Ajisaka.",
        "tree": {
            "sha": "4c8e5d29dec604089929d5a62d9310b256291f7e",
            "url": "https://api.github.com/repos/apache/hadoop/git/trees/4c8e5d29dec604089929d5a62d9310b256291f7e"
        },
        "url": "https://api.github.com/repos/apache/hadoop/git/commits/45a1c680c276c4501402f7bc4cebcf85a6fbc7f5",
        "comment_count": 0,
        "verification": {
            "verified": true,
            "reason": "valid",
            "signature": "-----BEGIN PGP SIGNATURE-----\n\niQJIBAABCgAyFiEE8F32UAoCGSJ7VmmQwe27nKQA/VAFAlsFJJoUHGFhamlzYWth\nQGFwYWNoZS5vcmcACgkQwe27nKQA/VCrlA//ea+9xw+Z1b9T14gG3gLlbRNIiTkI\nCgzppTkTbGBE1bth085SN7gIqkjWMfJ+8cUZ8ABia5i2HHAPCof697k37m1FuJS4\n82HtMzxWGXRk5PEEvcB2OpB+8pZEhC5cK5QLS7m3fHic3m9NRgQICh/5NRVCz0t6\naxJysyU4bIeCBTf+DDbgZ3khovYc/pkZnndeI5Hmzbbw87WLb9sdilpdrOTQLK6Q\nL7ahh//lN0u8pOqkIH47NrXkp4+zfQGLsR61ChCUj+rygjIfefFJRyvFOo+bZ+7k\n95zvOk09VNE8QzPdldsEVJ0w3xVMadRNOor47iScTuNzTM6srD50ryeMr95RmR1U\nS1tJFcKTSV/mYaMctJgIns8IEDjI2OjjAgbwIXSIbBhYJV6f7TQ83CnuvLWEhzAi\nFmfgPvl8QYhqAhGS6ZX07tdcmxtvnidSahdC5dPnYF++h1Ro69LGUk4SNUQYtXwA\no4zUNPJqc9f1FPIEeYZRZvHzJXThmznmtqwdwKqKcyItyCQ/QeaF/pH17tE3gMDl\ny1MnmzMbq22XF3R1+cVqeYE8RKYnOpX35iccxZAE6ESg9xqfU78SHBr7YIZ9oXao\noEPBYWl52vBlgEgmtZYxDz8ZKHiZWsk+KpSAyHrEAjWfr+55F5gfERnlZtNI6iRP\nbtLo54ZE9qHVgI8=\n=M7H4\n-----END PGP SIGNATURE-----",
            "payload": "tree 4c8e5d29dec604089929d5a62d9310b256291f7e\nparent 04219e55c8983f88573b10205dbca5411e744b35\nauthor Akira Ajisaka <aajisaka@apache.org> 1527063706 +0900\ncommitter Akira Ajisaka <aajisaka@apache.org> 1527063706 +0900\n\nAdditional check when unpacking archives. Contributed by Jason Lowe and Akira Ajisaka.\n",
            "verified_at": "2024-11-06T16:01:28Z"
        }
    },
    "url": "https://api.github.com/repos/apache/hadoop/commits/45a1c680c276c4501402f7bc4cebcf85a6fbc7f5",
    "html_url": "https://github.com/apache/hadoop/commit/45a1c680c276c4501402f7bc4cebcf85a6fbc7f5",
    "comments_url": "https://api.github.com/repos/apache/hadoop/commits/45a1c680c276c4501402f7bc4cebcf85a6fbc7f5/comments",
    "author": {
        "login": "aajisaka",
        "id": 3403122,
        "node_id": "MDQ6VXNlcjM0MDMxMjI=",
        "avatar_url": "https://avatars.githubusercontent.com/u/3403122?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/aajisaka",
        "html_url": "https://github.com/aajisaka",
        "followers_url": "https://api.github.com/users/aajisaka/followers",
        "following_url": "https://api.github.com/users/aajisaka/following{/other_user}",
        "gists_url": "https://api.github.com/users/aajisaka/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/aajisaka/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/aajisaka/subscriptions",
        "organizations_url": "https://api.github.com/users/aajisaka/orgs",
        "repos_url": "https://api.github.com/users/aajisaka/repos",
        "events_url": "https://api.github.com/users/aajisaka/events{/privacy}",
        "received_events_url": "https://api.github.com/users/aajisaka/received_events",
        "type": "User",
        "user_view_type": "public",
        "site_admin": false
    },
    "committer": {
        "login": "aajisaka",
        "id": 3403122,
        "node_id": "MDQ6VXNlcjM0MDMxMjI=",
        "avatar_url": "https://avatars.githubusercontent.com/u/3403122?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/aajisaka",
        "html_url": "https://github.com/aajisaka",
        "followers_url": "https://api.github.com/users/aajisaka/followers",
        "following_url": "https://api.github.com/users/aajisaka/following{/other_user}",
        "gists_url": "https://api.github.com/users/aajisaka/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/aajisaka/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/aajisaka/subscriptions",
        "organizations_url": "https://api.github.com/users/aajisaka/orgs",
        "repos_url": "https://api.github.com/users/aajisaka/repos",
        "events_url": "https://api.github.com/users/aajisaka/events{/privacy}",
        "received_events_url": "https://api.github.com/users/aajisaka/received_events",
        "type": "User",
        "user_view_type": "public",
        "site_admin": false
    },
    "parents": [
        {
            "sha": "04219e55c8983f88573b10205dbca5411e744b35",
            "url": "https://api.github.com/repos/apache/hadoop/commits/04219e55c8983f88573b10205dbca5411e744b35",
            "html_url": "https://github.com/apache/hadoop/commit/04219e55c8983f88573b10205dbca5411e744b35"
        }
    ],
    "stats": {
        "total": 59,
        "additions": 49,
        "deletions": 10
    },
    "files": [
        {
            "sha": "00381fee2785d149b9259754dc13784d97e5b8af",
            "filename": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileUtil.java",
            "status": "modified",
            "additions": 14,
            "deletions": 3,
            "changes": 17,
            "blob_url": "https://github.com/apache/hadoop/blob/45a1c680c276c4501402f7bc4cebcf85a6fbc7f5/hadoop-common-project%2Fhadoop-common%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fhadoop%2Ffs%2FFileUtil.java",
            "raw_url": "https://github.com/apache/hadoop/raw/45a1c680c276c4501402f7bc4cebcf85a6fbc7f5/hadoop-common-project%2Fhadoop-common%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fhadoop%2Ffs%2FFileUtil.java",
            "contents_url": "https://api.github.com/repos/apache/hadoop/contents/hadoop-common-project%2Fhadoop-common%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fhadoop%2Ffs%2FFileUtil.java?ref=45a1c680c276c4501402f7bc4cebcf85a6fbc7f5",
            "patch": "@@ -587,16 +587,21 @@ public static long getDU(File dir) {\n   public static void unZip(File inFile, File unzipDir) throws IOException {\n     Enumeration<? extends ZipEntry> entries;\n     ZipFile zipFile = new ZipFile(inFile);\n+    String targetDirPath = unzipDir.getCanonicalPath() + File.separator;\n \n     try {\n       entries = zipFile.entries();\n       while (entries.hasMoreElements()) {\n         ZipEntry entry = entries.nextElement();\n         if (!entry.isDirectory()) {\n+          File file = new File(unzipDir, entry.getName());\n+          if (!file.getCanonicalPath().startsWith(targetDirPath)) {\n+            throw new IOException(\"expanding \" + entry.getName()\n+                + \" would create file outside of \" + unzipDir);\n+          }\n           InputStream in = zipFile.getInputStream(entry);\n           try {\n-            File file = new File(unzipDir, entry.getName());\n-            if (!file.getParentFile().mkdirs()) {           \n+            if (!file.getParentFile().mkdirs()) {\n               if (!file.getParentFile().isDirectory()) {\n                 throw new IOException(\"Mkdirs failed to create \" + \n                                       file.getParentFile().toString());\n@@ -705,6 +710,13 @@ private static void unTarUsingJava(File inFile, File untarDir,\n   \n   private static void unpackEntries(TarArchiveInputStream tis,\n       TarArchiveEntry entry, File outputDir) throws IOException {\n+    String targetDirPath = outputDir.getCanonicalPath() + File.separator;\n+    File outputFile = new File(outputDir, entry.getName());\n+    if (!outputFile.getCanonicalPath().startsWith(targetDirPath)) {\n+      throw new IOException(\"expanding \" + entry.getName()\n+          + \" would create entry outside of \" + outputDir);\n+    }\n+\n     if (entry.isDirectory()) {\n       File subDir = new File(outputDir, entry.getName());\n       if (!subDir.mkdirs() && !subDir.isDirectory()) {\n@@ -719,7 +731,6 @@ private static void unpackEntries(TarArchiveInputStream tis,\n       return;\n     }\n \n-    File outputFile = new File(outputDir, entry.getName());\n     if (!outputFile.getParentFile().exists()) {\n       if (!outputFile.getParentFile().mkdirs()) {\n         throw new IOException(\"Mkdirs failed to create tar internal dir \""
        },
        {
            "sha": "7712535c6690bcb93eef3a88b592e904d6ee475b",
            "filename": "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFileUtil.java",
            "status": "modified",
            "additions": 35,
            "deletions": 7,
            "changes": 42,
            "blob_url": "https://github.com/apache/hadoop/blob/45a1c680c276c4501402f7bc4cebcf85a6fbc7f5/hadoop-common-project%2Fhadoop-common%2Fsrc%2Ftest%2Fjava%2Forg%2Fapache%2Fhadoop%2Ffs%2FTestFileUtil.java",
            "raw_url": "https://github.com/apache/hadoop/raw/45a1c680c276c4501402f7bc4cebcf85a6fbc7f5/hadoop-common-project%2Fhadoop-common%2Fsrc%2Ftest%2Fjava%2Forg%2Fapache%2Fhadoop%2Ffs%2FTestFileUtil.java",
            "contents_url": "https://api.github.com/repos/apache/hadoop/contents/hadoop-common-project%2Fhadoop-common%2Fsrc%2Ftest%2Fjava%2Forg%2Fapache%2Fhadoop%2Ffs%2FTestFileUtil.java?ref=45a1c680c276c4501402f7bc4cebcf85a6fbc7f5",
            "patch": "@@ -25,8 +25,9 @@\n import java.io.FileReader;\n import java.io.IOException;\n import java.io.OutputStream;\n-import java.net.URI;\n import java.io.PrintWriter;\n+import java.net.URI;\n+import java.nio.charset.StandardCharsets;\n import java.util.ArrayList;\n import java.util.Arrays;\n import java.util.Collections;\n@@ -40,6 +41,7 @@\n import org.apache.commons.logging.Log;\n import org.apache.commons.logging.LogFactory;\n import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.test.GenericTestUtils;\n import org.apache.hadoop.util.Shell;\n import org.apache.hadoop.util.StringUtils;\n import org.apache.tools.tar.TarEntry;\n@@ -708,10 +710,8 @@ public void testCreateLocalTempFile() throws IOException {\n   \n   @Test (timeout = 30000)\n   public void testUnZip() throws IOException {\n-    // make sa simple zip\n     setupDirs();\n-    \n-    // make a simple tar:\n+    // make a simple zip\n     final File simpleZip = new File(del, FILE);\n     OutputStream os = new FileOutputStream(simpleZip); \n     ZipOutputStream tos = new ZipOutputStream(os);\n@@ -728,7 +728,7 @@ public void testUnZip() throws IOException {\n       tos.close();\n     }\n     \n-    // successfully untar it into an existing dir:\n+    // successfully unzip it into an existing dir:\n     FileUtil.unZip(simpleZip, tmp);\n     // check result:\n     assertTrue(new File(tmp, \"foo\").exists());\n@@ -743,8 +743,36 @@ public void testUnZip() throws IOException {\n     } catch (IOException ioe) {\n       // okay\n     }\n-  }  \n-  \n+  }\n+\n+  @Test (timeout = 30000)\n+  public void testUnZip2() throws IOException {\n+    setupDirs();\n+    // make a simple zip\n+    final File simpleZip = new File(del, FILE);\n+    OutputStream os = new FileOutputStream(simpleZip);\n+    try (ZipOutputStream tos = new ZipOutputStream(os)) {\n+      // Add an entry that contains invalid filename\n+      ZipEntry ze = new ZipEntry(\"../foo\");\n+      byte[] data = \"some-content\".getBytes(StandardCharsets.UTF_8);\n+      ze.setSize(data.length);\n+      tos.putNextEntry(ze);\n+      tos.write(data);\n+      tos.closeEntry();\n+      tos.flush();\n+      tos.finish();\n+    }\n+\n+    // Unzip it into an existing dir\n+    try {\n+      FileUtil.unZip(simpleZip, tmp);\n+      Assert.fail(\"unZip should throw IOException.\");\n+    } catch (IOException e) {\n+      GenericTestUtils.assertExceptionContains(\n+          \"would create file outside of\", e);\n+    }\n+  }\n+\n   @Test (timeout = 30000)\n   /*\n    * Test method copy(FileSystem srcFS, Path src, File dst, boolean deleteSource, Configuration conf)"
        }
    ]
}