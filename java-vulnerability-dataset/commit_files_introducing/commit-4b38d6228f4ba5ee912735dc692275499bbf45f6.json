{
    "sha": "4b38d6228f4ba5ee912735dc692275499bbf45f6",
    "node_id": "MDY6Q29tbWl0MjA2NDI3OjRiMzhkNjIyOGY0YmE1ZWU5MTI3MzVkYzY5MjI3NTQ5OWJiZjQ1ZjY=",
    "commit": {
        "author": {
            "name": "tballison",
            "email": "tallison@mitre.org",
            "date": "2018-05-21T17:10:40Z"
        },
        "committer": {
            "name": "tballison",
            "email": "tallison@mitre.org",
            "date": "2018-05-21T17:10:40Z"
        },
        "message": "TIKA-2645 for tika-core",
        "tree": {
            "sha": "6b23f68d995bddab52c1f7262f39256780fb2be4",
            "url": "https://api.github.com/repos/apache/tika/git/trees/6b23f68d995bddab52c1f7262f39256780fb2be4"
        },
        "url": "https://api.github.com/repos/apache/tika/git/commits/4b38d6228f4ba5ee912735dc692275499bbf45f6",
        "comment_count": 0,
        "verification": {
            "verified": false,
            "reason": "unsigned",
            "signature": null,
            "payload": null,
            "verified_at": null
        }
    },
    "url": "https://api.github.com/repos/apache/tika/commits/4b38d6228f4ba5ee912735dc692275499bbf45f6",
    "html_url": "https://github.com/apache/tika/commit/4b38d6228f4ba5ee912735dc692275499bbf45f6",
    "comments_url": "https://api.github.com/repos/apache/tika/commits/4b38d6228f4ba5ee912735dc692275499bbf45f6/comments",
    "author": {
        "login": "tballison",
        "id": 6739646,
        "node_id": "MDQ6VXNlcjY3Mzk2NDY=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6739646?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/tballison",
        "html_url": "https://github.com/tballison",
        "followers_url": "https://api.github.com/users/tballison/followers",
        "following_url": "https://api.github.com/users/tballison/following{/other_user}",
        "gists_url": "https://api.github.com/users/tballison/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/tballison/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/tballison/subscriptions",
        "organizations_url": "https://api.github.com/users/tballison/orgs",
        "repos_url": "https://api.github.com/users/tballison/repos",
        "events_url": "https://api.github.com/users/tballison/events{/privacy}",
        "received_events_url": "https://api.github.com/users/tballison/received_events",
        "type": "User",
        "user_view_type": "public",
        "site_admin": false
    },
    "committer": {
        "login": "tballison",
        "id": 6739646,
        "node_id": "MDQ6VXNlcjY3Mzk2NDY=",
        "avatar_url": "https://avatars.githubusercontent.com/u/6739646?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/tballison",
        "html_url": "https://github.com/tballison",
        "followers_url": "https://api.github.com/users/tballison/followers",
        "following_url": "https://api.github.com/users/tballison/following{/other_user}",
        "gists_url": "https://api.github.com/users/tballison/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/tballison/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/tballison/subscriptions",
        "organizations_url": "https://api.github.com/users/tballison/orgs",
        "repos_url": "https://api.github.com/users/tballison/repos",
        "events_url": "https://api.github.com/users/tballison/events{/privacy}",
        "received_events_url": "https://api.github.com/users/tballison/received_events",
        "type": "User",
        "user_view_type": "public",
        "site_admin": false
    },
    "parents": [
        {
            "sha": "12693ea18f1a05894272aa3a9293d41215f63c06",
            "url": "https://api.github.com/repos/apache/tika/commits/12693ea18f1a05894272aa3a9293d41215f63c06",
            "html_url": "https://github.com/apache/tika/commit/12693ea18f1a05894272aa3a9293d41215f63c06"
        }
    ],
    "stats": {
        "total": 581,
        "additions": 495,
        "deletions": 86
    },
    "files": [
        {
            "sha": "63c0edd6ed9d71766e06fa111f58e1ba81655436",
            "filename": "tika-core/src/main/java/org/apache/tika/detect/XmlRootExtractor.java",
            "status": "modified",
            "additions": 8,
            "deletions": 15,
            "changes": 23,
            "blob_url": "https://github.com/apache/tika/blob/4b38d6228f4ba5ee912735dc692275499bbf45f6/tika-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Ftika%2Fdetect%2FXmlRootExtractor.java",
            "raw_url": "https://github.com/apache/tika/raw/4b38d6228f4ba5ee912735dc692275499bbf45f6/tika-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Ftika%2Fdetect%2FXmlRootExtractor.java",
            "contents_url": "https://api.github.com/repos/apache/tika/contents/tika-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Ftika%2Fdetect%2FXmlRootExtractor.java?ref=4b38d6228f4ba5ee912735dc692275499bbf45f6",
            "patch": "@@ -19,15 +19,15 @@\n import java.io.ByteArrayInputStream;\n import java.io.InputStream;\n \n-import javax.xml.XMLConstants;\n import javax.xml.namespace.QName;\n-import javax.xml.parsers.SAXParserFactory;\n+import javax.xml.parsers.SAXParser;\n \n+import org.apache.tika.exception.TikaException;\n import org.apache.tika.io.CloseShieldInputStream;\n import org.apache.tika.sax.OfflineContentHandler;\n+import org.apache.tika.utils.XMLReaderUtils;\n import org.xml.sax.Attributes;\n import org.xml.sax.SAXException;\n-import org.xml.sax.SAXNotRecognizedException;\n import org.xml.sax.helpers.DefaultHandler;\n \n /**\n@@ -47,22 +47,15 @@ public QName extractRootElement(byte[] data) {\n      */\n     public QName extractRootElement(InputStream stream) {\n         ExtractorHandler handler = new ExtractorHandler();\n+        SAXParser parser = null;\n         try {\n-            SAXParserFactory factory = SAXParserFactory.newInstance();\n-            factory.setNamespaceAware(true);\n-            factory.setValidating(false);\n-            try {\n-                factory.setFeature(XMLConstants.FEATURE_SECURE_PROCESSING, true);\n-            } catch (SAXNotRecognizedException e) {\n-                // TIKA-271 and TIKA-1000: Some XML parsers do not support the secure-processing\n-                // feature, even though it's required by JAXP in Java 5. Ignoring\n-                // the exception is fine here, deployments without this feature\n-                // are inherently vulnerable to XML denial-of-service attacks.\n-            }\n-            factory.newSAXParser().parse(\n+            parser = XMLReaderUtils.acquireSAXParser();\n+            parser.parse(\n                     new CloseShieldInputStream(stream),\n                     new OfflineContentHandler(handler));\n         } catch (Exception ignore) {\n+        } finally {\n+                XMLReaderUtils.releaseParser(parser);\n         }\n         return handler.rootElement;\n     }"
        },
        {
            "sha": "71561a82dddf4d6952392df3cd107b7d7448e5c0",
            "filename": "tika-core/src/main/java/org/apache/tika/mime/MimeTypesReader.java",
            "status": "modified",
            "additions": 106,
            "deletions": 7,
            "changes": 113,
            "blob_url": "https://github.com/apache/tika/blob/4b38d6228f4ba5ee912735dc692275499bbf45f6/tika-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Ftika%2Fmime%2FMimeTypesReader.java",
            "raw_url": "https://github.com/apache/tika/raw/4b38d6228f4ba5ee912735dc692275499bbf45f6/tika-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Ftika%2Fmime%2FMimeTypesReader.java",
            "contents_url": "https://api.github.com/repos/apache/tika/contents/tika-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Ftika%2Fmime%2FMimeTypesReader.java?ref=4b38d6228f4ba5ee912735dc692275499bbf45f6",
            "patch": "@@ -33,7 +33,11 @@\n import java.util.ArrayList;\n import java.util.Collections;\n import java.util.List;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n \n+import org.apache.tika.exception.TikaException;\n import org.w3c.dom.Document;\n import org.xml.sax.Attributes;\n import org.xml.sax.InputSource;\n@@ -99,7 +103,22 @@\n  * @see <a href=\"https://freedesktop.org/wiki/Specifications/shared-mime-info-spec/\">https://freedesktop.org/wiki/Specifications/shared-mime-info-spec/</a>\n  */\n public class MimeTypesReader extends DefaultHandler implements MimeTypesReaderMetKeys {\n-    protected final MimeTypes types;\n+    /**\n+     * Parser pool size\n+     */\n+    private static int POOL_SIZE = 10;\n+\n+    private static final ReentrantReadWriteLock READ_WRITE_LOCK = new ReentrantReadWriteLock();\n+\n+    private static ArrayBlockingQueue<SAXParser> SAX_PARSERS = new ArrayBlockingQueue<>(POOL_SIZE);\n+\n+    static {\n+        try {\n+            setPoolSize(POOL_SIZE);\n+        } catch (TikaException e) {\n+            throw new RuntimeException(\"problem initializing SAXParser pool\", e);\n+        }\n+    }    protected final MimeTypes types;\n \n     /** Current type */\n     protected MimeType type = null;\n@@ -113,23 +132,24 @@ protected MimeTypesReader(MimeTypes types) {\n     }\n \n     public void read(InputStream stream) throws IOException, MimeTypeException {\n+        SAXParser parser = null;\n         try {\n-            SAXParserFactory factory = SAXParserFactory.newInstance();\n-            factory.setNamespaceAware(false);\n-            factory.setFeature(\n-                    XMLConstants.FEATURE_SECURE_PROCESSING, true);\n-            SAXParser parser = factory.newSAXParser();\n+\n+            parser = acquireSAXParser();\n             parser.parse(stream, this);\n-        } catch (ParserConfigurationException e) {\n+        } catch (TikaException e) {\n             throw new MimeTypeException(\"Unable to create an XML parser\", e);\n         } catch (SAXException e) {\n             throw new MimeTypeException(\"Invalid type configuration\", e);\n+        } finally {\n+            releaseParser(parser);\n         }\n     }\n \n     public void read(Document document) throws MimeTypeException {\n         try {\n             TransformerFactory factory = TransformerFactory.newInstance();\n+            factory.setFeature(XMLConstants.FEATURE_SECURE_PROCESSING, true);\n             Transformer transformer = factory.newTransformer();\n             transformer.transform(new DOMSource(document), new SAXResult(this));\n         } catch (TransformerException e) {\n@@ -291,5 +311,84 @@ public List<Clause> getClauses() {\n         }\n \n     }\n+    /**\n+     * Acquire a SAXParser from the pool; create one if it\n+     * doesn't exist.  Make sure to {@link #releaseParser(SAXParser)} in\n+     * a <code>finally</code> block every time you call this.\n+     *\n+     * @return a SAXParser\n+     * @throws TikaException\n+     */\n+    public static SAXParser acquireSAXParser()\n+            throws TikaException {\n+        while (true) {\n+            SAXParser parser = null;\n+            try {\n+                READ_WRITE_LOCK.readLock().lock();\n+                parser = SAX_PARSERS.poll(10, TimeUnit.MILLISECONDS);\n+            } catch (InterruptedException e) {\n+                throw new TikaException(\"interrupted while waiting for SAXParser\", e);\n+            } finally {\n+                READ_WRITE_LOCK.readLock().unlock();\n \n+            }\n+            if (parser != null) {\n+                return parser;\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Return parser to the pool for reuse\n+     *\n+     * @param parser parser to return\n+     */\n+    public static void releaseParser(SAXParser parser) {\n+        try {\n+            parser.reset();\n+        } catch (UnsupportedOperationException e) {\n+            //ignore\n+        }\n+        try {\n+            READ_WRITE_LOCK.readLock().lock();\n+            //if there are extra parsers (e.g. after a reset of the pool to a smaller size),\n+            // this parser will not be added and will then be gc'd\n+            SAX_PARSERS.offer(parser);\n+        } finally {\n+            READ_WRITE_LOCK.readLock().unlock();\n+        }\n+    }\n+\n+    /**\n+     * Set the pool size for cached XML parsers.\n+     *\n+     * @param poolSize\n+     */\n+    public static void setPoolSize(int poolSize) throws TikaException {\n+        try {\n+            //stop the world with a write lock\n+            //parsers that are currently in use will be offered, but not\n+            //accepted and will be gc'd\n+            READ_WRITE_LOCK.writeLock().lock();\n+            SAX_PARSERS = new ArrayBlockingQueue<>(poolSize);\n+            for (int i = 0; i < poolSize; i++) {\n+                SAX_PARSERS.offer(newSAXParser());\n+            }\n+            POOL_SIZE = poolSize;\n+        } finally {\n+            READ_WRITE_LOCK.writeLock().unlock();\n+        }\n+    }\n+\n+    private static SAXParser newSAXParser() throws TikaException {\n+        SAXParserFactory factory = SAXParserFactory.newInstance();\n+        factory.setNamespaceAware(false);\n+        try {\n+            factory.setFeature(\n+                    XMLConstants.FEATURE_SECURE_PROCESSING, true);\n+            return factory.newSAXParser();\n+        } catch (ParserConfigurationException|SAXException e) {\n+            throw new TikaException(\"prooblem creating SAX parser factory\", e);\n+        }\n+    }\n }"
        },
        {
            "sha": "2a3afcde49abf2d56fd1206e1c5cad2bd49e60b5",
            "filename": "tika-core/src/main/java/org/apache/tika/parser/ParseContext.java",
            "status": "modified",
            "additions": 33,
            "deletions": 0,
            "changes": 33,
            "blob_url": "https://github.com/apache/tika/blob/4b38d6228f4ba5ee912735dc692275499bbf45f6/tika-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Ftika%2Fparser%2FParseContext.java",
            "raw_url": "https://github.com/apache/tika/raw/4b38d6228f4ba5ee912735dc692275499bbf45f6/tika-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Ftika%2Fparser%2FParseContext.java",
            "contents_url": "https://api.github.com/repos/apache/tika/contents/tika-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Ftika%2Fparser%2FParseContext.java?ref=4b38d6228f4ba5ee912735dc692275499bbf45f6",
            "patch": "@@ -52,6 +52,7 @@ public class ParseContext implements Serializable {\n     /** Serial version UID. */\n     private static final long serialVersionUID = -5921436862145826534L;\n \n+    private final XMLReaderUtils xmlReaderUtils = new XMLReaderUtils();\n     /** Map of objects in this context */\n     private final Map<String, Object> context = new HashMap<String, Object>();\n \n@@ -137,6 +138,38 @@ public SAXParser getSAXParser() throws TikaException {\n         }\n     }\n \n+    /**\n+     * Returns the SAX parser specified in this parsing context. If a parser\n+     * is not explicitly specified, then one is acquired from the pool.\n+     * <p>\n+     * Make sure to {@link #releaseParser(SAXParser)} in\n+     * a <code>finally</code> block every time you call this.\n+     * </p>\n+     *\n+     * @return SAXParser\n+     * @throws TikaException\n+     */\n+    public SAXParser acquireSAXParser() throws TikaException {\n+        if (context.containsKey(SAXParser.class)) {\n+            return get(SAXParser.class);\n+        }\n+        return xmlReaderUtils.acquireSAXParser();\n+    }\n+\n+    /**\n+     * If the context already has a SAXParser, this is a no-op.\n+     * Otherwise, this returns the parser to the pool\n+     *\n+     * @param parser\n+     * @throws TikaException\n+     */\n+    public void releaseParser(SAXParser parser) throws TikaException {\n+        if (context.containsKey(SAXParser.class)) {\n+            return;\n+        }\n+        xmlReaderUtils.releaseParser(parser);\n+    }\n+\n     /**\n      * Returns the SAX parser factory specified in this parsing context.\n      * If a factory is not explicitly specified, then a default factory"
        },
        {
            "sha": "4ed58b4630f3c1c239abdc623472ee0e90b003ae",
            "filename": "tika-core/src/main/java/org/apache/tika/utils/XMLReaderUtils.java",
            "status": "modified",
            "additions": 113,
            "deletions": 16,
            "changes": 129,
            "blob_url": "https://github.com/apache/tika/blob/4b38d6228f4ba5ee912735dc692275499bbf45f6/tika-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Ftika%2Futils%2FXMLReaderUtils.java",
            "raw_url": "https://github.com/apache/tika/raw/4b38d6228f4ba5ee912735dc692275499bbf45f6/tika-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Ftika%2Futils%2FXMLReaderUtils.java",
            "contents_url": "https://api.github.com/repos/apache/tika/contents/tika-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Ftika%2Futils%2FXMLReaderUtils.java?ref=4b38d6228f4ba5ee912735dc692275499bbf45f6",
            "patch": "@@ -38,9 +38,12 @@\n import javax.xml.transform.TransformerConfigurationException;\n import javax.xml.transform.TransformerFactory;\n import javax.xml.transform.TransformerFactoryConfigurationError;\n-\n import java.io.IOException;\n+import java.io.Serializable;\n import java.io.StringReader;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n import java.util.logging.Level;\n import java.util.logging.Logger;\n \n@@ -49,9 +52,33 @@\n  * to use the {@link org.apache.tika.sax.OfflineContentHandler} to guard against\n  * XML External Entity attacks.\n  */\n-public class XMLReaderUtils {\n+public class XMLReaderUtils implements Serializable {\n+\n+    /**\n+     * Serial version UID\n+     */\n+    private static final long serialVersionUID = 6110455808615143122L;\n+\n     private static final Logger LOG = Logger.getLogger(XMLReaderUtils.class.getName());\n \n+    /**\n+     * Parser pool size\n+     */\n+    private static int POOL_SIZE = 10;\n+\n+    private static final ReentrantReadWriteLock READ_WRITE_LOCK = new ReentrantReadWriteLock();\n+\n+    private static ArrayBlockingQueue<SAXParser> SAX_PARSERS = new ArrayBlockingQueue<>(POOL_SIZE);\n+\n+    static {\n+        try {\n+            setPoolSize(POOL_SIZE);\n+        } catch (TikaException e) {\n+            throw new RuntimeException(\"problem initializing SAXParser pool\", e);\n+        }\n+    }\n+\n+\n     private static final EntityResolver IGNORING_SAX_ENTITY_RESOLVER = new EntityResolver() {\n         public InputSource resolveEntity(String publicId, String systemId) throws SAXException, IOException {\n             return new InputSource(new StringReader(\"\"));\n@@ -72,10 +99,10 @@ public Object resolveEntity(String publicID, String systemID, String baseURI, St\n      * is not explicitly specified, then one is created using the specified\n      * or the default SAX parser.\n      *\n-     * @see #getSAXParser()\n-     * @since Apache Tika 1.13\n      * @return XMLReader\n      * @throws TikaException\n+     * @see #getSAXParser()\n+     * @since Apache Tika 1.13\n      */\n     public static XMLReader getXMLReader() throws TikaException {\n         XMLReader reader;\n@@ -96,12 +123,11 @@ public static XMLReader getXMLReader() throws TikaException {\n      * Make sure to wrap your handler in the {@link org.apache.tika.sax.OfflineContentHandler} to\n      * prevent XML External Entity attacks\n      * </p>\n-\n      *\n-     * @see #getSAXParserFactory()\n-     * @since Apache Tika 0.8\n      * @return SAX parser\n      * @throws TikaException if a SAX parser could not be created\n+     * @see #getSAXParserFactory()\n+     * @since Apache Tika 0.8\n      */\n     public static SAXParser getSAXParser() throws TikaException {\n         try {\n@@ -124,8 +150,8 @@ public static SAXParser getSAXParser() throws TikaException {\n      * prevent XML External Entity attacks\n      * </p>\n      *\n-     * @since Apache Tika 0.8\n      * @return SAX parser factory\n+     * @since Apache Tika 0.8\n      */\n     public static SAXParserFactory getSAXParserFactory() {\n         SAXParserFactory factory = SAXParserFactory.newInstance();\n@@ -154,8 +180,8 @@ public static SAXParserFactory getSAXParserFactory() {\n      * configured to be namespace-aware and to apply reasonable security\n      * features.\n      *\n-     * @since Apache Tika 1.13\n      * @return DOM parser factory\n+     * @since Apache Tika 1.13\n      */\n     public static DocumentBuilderFactory getDocumentBuilderFactory() {\n         //borrowed from Apache POI\n@@ -179,8 +205,8 @@ public static DocumentBuilderFactory getDocumentBuilderFactory() {\n      * configured to apply an {@link #IGNORING_SAX_ENTITY_RESOLVER},\n      * and it sets the ErrorHandler to <code>null</code>.\n      *\n-     * @since Apache Tika 1.13\n      * @return DOM Builder\n+     * @since Apache Tika 1.13\n      */\n     public static DocumentBuilder getDocumentBuilder() throws TikaException {\n         try {\n@@ -201,8 +227,8 @@ public static DocumentBuilder getDocumentBuilder() throws TikaException {\n      * configured to be namespace-aware and to apply reasonable security\n      * using the {@link #IGNORING_STAX_ENTITY_RESOLVER}.\n      *\n-     * @since Apache Tika 1.13\n      * @return StAX input factory\n+     * @since Apache Tika 1.13\n      */\n     public static XMLInputFactory getXMLInputFactory() {\n         XMLInputFactory factory = XMLInputFactory.newFactory();\n@@ -218,9 +244,9 @@ private static void trySetSAXFeature(DocumentBuilderFactory documentBuilderFacto\n         try {\n             documentBuilderFactory.setFeature(feature, enabled);\n         } catch (Exception e) {\n-            LOG.log(Level.WARNING, \"SAX Feature unsupported: \"+feature, e);\n+            LOG.log(Level.WARNING, \"SAX Feature unsupported: \" + feature, e);\n         } catch (AbstractMethodError ame) {\n-            LOG.log(Level.WARNING, \"Cannot set SAX feature because outdated XML parser in classpath: \"+ feature, ame);\n+            LOG.log(Level.WARNING, \"Cannot set SAX feature because outdated XML parser in classpath: \" + feature, ame);\n         }\n     }\n \n@@ -234,13 +260,13 @@ private static void tryToSetStaxProperty(XMLInputFactory factory, String key, bo\n \n     /**\n      * Returns a new transformer\n-     * \n+     * <p>\n      * The transformer instance is configured to to use\n      * {@link XMLConstants#FEATURE_SECURE_PROCESSING secure XML processing}.\n      *\n-     * @since Apache Tika 1.17\n      * @return Transformer\n      * @throws TikaException when the transformer can not be created\n+     * @since Apache Tika 1.17\n      */\n     public static Transformer getTransformer() throws TikaException {\n         try {\n@@ -249,7 +275,78 @@ public static Transformer getTransformer() throws TikaException {\n             return transformerFactory.newTransformer();\n         } catch (TransformerConfigurationException | TransformerFactoryConfigurationError e) {\n             throw new TikaException(\"Transformer not available\", e);\n-        }        \n+        }\n     }\n \n+    /**\n+     * Acquire a SAXParser from the pool; create one if it\n+     * doesn't exist.  Make sure to {@link #releaseParser(SAXParser)} in\n+     * a <code>finally</code> block every time you call this.\n+     *\n+     * @return a SAXParser\n+     * @throws TikaException\n+     */\n+    public static SAXParser acquireSAXParser()\n+            throws TikaException {\n+        while (true) {\n+            SAXParser parser = null;\n+            try {\n+                READ_WRITE_LOCK.readLock().lock();\n+                parser = SAX_PARSERS.poll(10, TimeUnit.MILLISECONDS);\n+            } catch (InterruptedException e) {\n+                throw new TikaException(\"interrupted while waiting for SAXParser\", e);\n+            } finally {\n+                READ_WRITE_LOCK.readLock().unlock();\n+\n+            }\n+            if (parser != null) {\n+                return parser;\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Return parser to the pool for reuse\n+     *\n+     * @param parser parser to return\n+     */\n+    public static void releaseParser(SAXParser parser) {\n+        try {\n+            parser.reset();\n+        } catch (UnsupportedOperationException e) {\n+            //ignore\n+        }\n+        try {\n+            READ_WRITE_LOCK.readLock().lock();\n+            //if there are extra parsers (e.g. after a reset of the pool to a smaller size),\n+            // this parser will not be added and will then be gc'd\n+            boolean success = SAX_PARSERS.offer(parser);\n+        } finally {\n+            READ_WRITE_LOCK.readLock().unlock();\n+        }\n+    }\n+\n+    /**\n+     * Set the pool size for cached XML parsers.\n+     *\n+     * @param poolSize\n+     */\n+    public static void setPoolSize(int poolSize) throws TikaException {\n+        try {\n+            //stop the world with a write lock.\n+            //parsers that are currently in use will be offered, but not\n+            //accepted and will be gc'd\n+            READ_WRITE_LOCK.writeLock().lock();\n+            if (SAX_PARSERS.size() == poolSize) {\n+                return;\n+            }\n+            SAX_PARSERS = new ArrayBlockingQueue<>(poolSize);\n+            for (int i = 0; i < poolSize; i++) {\n+                SAX_PARSERS.offer(getSAXParser());\n+            }\n+            POOL_SIZE = poolSize;\n+        } finally {\n+            READ_WRITE_LOCK.writeLock().unlock();\n+        }\n+    }\n }"
        },
        {
            "sha": "3d5094b87bb137e43cc0894eeefeef3b8c0ba2de",
            "filename": "tika-core/src/test/java/org/apache/tika/MultiThreadedTikaTest.java",
            "status": "modified",
            "additions": 186,
            "deletions": 44,
            "changes": 230,
            "blob_url": "https://github.com/apache/tika/blob/4b38d6228f4ba5ee912735dc692275499bbf45f6/tika-core%2Fsrc%2Ftest%2Fjava%2Forg%2Fapache%2Ftika%2FMultiThreadedTikaTest.java",
            "raw_url": "https://github.com/apache/tika/raw/4b38d6228f4ba5ee912735dc692275499bbf45f6/tika-core%2Fsrc%2Ftest%2Fjava%2Forg%2Fapache%2Ftika%2FMultiThreadedTikaTest.java",
            "contents_url": "https://api.github.com/repos/apache/tika/contents/tika-core%2Fsrc%2Ftest%2Fjava%2Forg%2Fapache%2Ftika%2FMultiThreadedTikaTest.java?ref=4b38d6228f4ba5ee912735dc692275499bbf45f6",
            "patch": "@@ -17,17 +17,22 @@\n \n package org.apache.tika;\n \n+import org.apache.tika.detect.Detector;\n+import org.apache.tika.detect.XmlRootExtractor;\n+import org.apache.tika.exception.TikaException;\n+import org.apache.tika.io.TikaInputStream;\n import org.apache.tika.metadata.Metadata;\n+import org.apache.tika.mime.MediaType;\n import org.apache.tika.parser.AutoDetectParser;\n import org.apache.tika.parser.ParseContext;\n import org.apache.tika.parser.Parser;\n import org.apache.tika.parser.RecursiveParserWrapper;\n import org.apache.tika.sax.AbstractRecursiveParserWrapperHandler;\n import org.apache.tika.sax.BasicContentHandlerFactory;\n import org.apache.tika.sax.RecursiveParserWrapperHandler;\n-import org.junit.Test;\n-import org.xml.sax.helpers.DefaultHandler;\n+import org.apache.tika.utils.XMLReaderUtils;\n \n+import javax.xml.namespace.QName;\n import java.io.FileFilter;\n import java.io.IOException;\n import java.io.InputStream;\n@@ -40,7 +45,6 @@\n import java.nio.file.attribute.BasicFileAttributes;\n import java.util.ArrayList;\n import java.util.List;\n-import java.util.Locale;\n import java.util.Map;\n import java.util.Random;\n import java.util.concurrent.Callable;\n@@ -57,60 +61,125 @@\n public class MultiThreadedTikaTest extends TikaTest {\n     //TODO: figure out how to make failures reproducible a la Lucene/Solr with a seed\n     //TODO: Consider randomizing the Locale and timezone, like Lucene/Solr...\n+    XmlRootExtractor ex = new XmlRootExtractor();\n \n     /**\n-     * This calls {@link #testEach(Path[], int, int)} and then {@link #testAll(Path[], int, int)}\n+     * This calls {@link #testEach(Path[], ParseContext[], int, int)} and then {@link #testAll(Path[], ParseContext[], int, int)}\n      *\n-     * @param numThreads number of threads to use\n+     * @param numThreads    number of threads to use\n      * @param numIterations number of iterations per thread\n-     * @param filter file filter to select files from \"/test-documents\"; if <code>null</code>,\n-     *               all files will be used\n+     * @param filter        file filter to select files from \"/test-documents\"; if <code>null</code>,\n+     *                      all files will be used\n      * @throws Exception\n      */\n-    protected void testMultiThreaded(int numThreads, int numIterations, FileFilter filter) throws Exception {\n+    protected void testMultiThreaded(ParseContext[] parseContext, int numThreads, int numIterations, FileFilter filter) throws Exception {\n         Path[] allFiles = getTestFiles(filter);\n-        //testEach(allFiles, numThreads, numIterations);\n-        testAll(allFiles, numThreads, numIterations);\n+        testEach(allFiles, parseContext, numThreads, numIterations);\n+        testAll(allFiles, parseContext, numThreads, numIterations);\n+    }\n+\n+    public void testDetector(Detector detector, int numThreads, int numIterations, FileFilter filter, int randomlyResizeSAXPool) throws Exception {\n+        Path[] files = getTestFiles(filter);\n+        testDetectorEach(detector, files, numThreads, numIterations, randomlyResizeSAXPool);\n+        testDetectorOnAll(detector, files, numThreads, numIterations, randomlyResizeSAXPool);\n+    }\n+\n+    void testDetectorEach(Detector detector, Path[] files, int numThreads, int numIterations, int randomlyResizeSAXPool) {\n+        for (Path p : files) {\n+            Path[] toTest = new Path[1];\n+            toTest[0] = p;\n+            testDetectorOnAll(detector, toTest, numThreads, numIterations, randomlyResizeSAXPool);\n+        }\n+    }\n+\n+    private void testDetectorOnAll(Detector detector, Path[] toTest, int numThreads, int numIterations, int randomlyResizeSAXPool) {\n+        Map<Path, MediaType> truth = getBaselineDetection(detector, toTest);\n+        //if all files caused an exception\n+        if (truth.size() == 0) {\n+            return;\n+        }\n+        //only those that parsed without exception\n+        Path[] testFiles = new Path[truth.size()];\n+        int j = 0;\n+        for (Path testFile : truth.keySet()) {\n+            testFiles[j++] = testFile;\n+        }\n+        int actualThreadCount = numThreads + ((randomlyResizeSAXPool > 0) ? randomlyResizeSAXPool : 0);\n+        ExecutorService ex = Executors.newFixedThreadPool(actualThreadCount);\n+        try {\n+            _testDetectorOnAll(detector, testFiles, numThreads, numIterations, truth, ex, randomlyResizeSAXPool);\n+        } finally {\n+            ex.shutdown();\n+            ex.shutdownNow();\n+        }\n+    }\n+\n+    private void _testDetectorOnAll(Detector detector, Path[] testFiles, int numThreads,\n+                                    int numIterations, Map<Path, MediaType> truth, ExecutorService ex, int randomlyResizeSAXPool) {\n+        ExecutorCompletionService<Integer> executorCompletionService = new ExecutorCompletionService<>(ex);\n+\n+        executorCompletionService.submit(new SAXPoolResizer(randomlyResizeSAXPool));\n+        for (int i = 0; i < numThreads; i++) {\n+            executorCompletionService.submit(new TikaDetectorRunner(detector, numIterations, testFiles, truth));\n+        }\n+\n+        int completed = 0;\n+        while (completed < numThreads) {\n+            //TODO: add a maximum timeout threshold\n+\n+            Future<Integer> future = null;\n+            try {\n+                future = executorCompletionService.poll(1000, TimeUnit.MILLISECONDS);\n+                if (future != null) {\n+                    future.get();//trigger exceptions from thread\n+                    completed++;\n+                }\n+            } catch (InterruptedException | ExecutionException e) {\n+                throw new RuntimeException(e);\n+            }\n+        }\n+        ex.shutdown();\n+        ex.shutdownNow();\n     }\n \n     /**\n-     *  Test each file, one at a time in multiple threads.\n-     *  This was required to test TIKA-2519 in a reasonable\n-     *  amount of time.  This forced the parser to use the\n-     *  same underlying memory structurees because it was the same file.\n-     *  This is stricter than I think our agreement with clients is\n-     *  because this run tests on literally the same file and\n-     *  not a copy of the file per thread.  Let's leave this as is\n-     *  unless there's a good reason to create a separate copy per thread.\n+     * Test each file, one at a time in multiple threads.\n+     * This was required to test TIKA-2519 in a reasonable\n+     * amount of time.  This forced the parser to use the\n+     * same underlying memory structures because it was the same file.\n+     * This is stricter than I think our agreement with clients is\n+     * because this run tests on literally the same file and\n+     * not a copy of the file per thread.  Let's leave this as is\n+     * unless there's a good reason to create a separate copy per thread.\n      *\n-     * @param files files to test, one at a time\n-     * @param numThreads number of threads to use\n+     * @param files         files to test, one at a time\n+     * @param numThreads    number of threads to use\n      * @param numIterations number of iterations per thread\n      */\n-    protected void testEach(Path[] files, int numThreads, int numIterations) {\n+    protected void testEach(Path[] files, ParseContext[] parseContext, int numThreads, int numIterations) {\n         for (Path p : files) {\n             Path[] toTest = new Path[1];\n             toTest[0] = p;\n-            testAll(toTest, numThreads, numIterations);\n+            testAll(toTest, parseContext, numThreads, numIterations);\n         }\n     }\n \n     /**\n      * This tests all files together.  Each parser randomly selects\n      * a file from the array.  Two parsers could wind up parsing the\n      * same file at the same time.  Good.\n-     *\n+     * <p>\n      * In the current implementation, this gets ground truth only\n      * from files that do not throw exceptions.  This will ignore\n      * files that cause exceptions.\n      *\n-     * @param files files to parse\n-     * @param numThreads number of parser threads\n+     * @param files         files to parse\n+     * @param numThreads    number of parser threads\n      * @param numIterations number of iterations per parser\n      */\n-    protected void testAll(Path[] files, int numThreads, int numIterations) {\n+    protected void testAll(Path[] files, ParseContext[] parseContext, int numThreads, int numIterations) {\n \n-        Map<Path, Extract> truth = getBaseline(files);\n+        Map<Path, Extract> truth = getBaseline(files, parseContext[0]);\n         //if all files caused an exception\n         if (truth.size() == 0) {\n             return;\n@@ -124,24 +193,23 @@ protected void testAll(Path[] files, int numThreads, int numIterations) {\n \n         ExecutorService ex = Executors.newFixedThreadPool(numThreads);\n         try {\n-            _testAll(testFiles, numThreads, numIterations, truth, ex);\n+            _testAll(testFiles, parseContext, numThreads, numIterations, truth, ex);\n         } finally {\n             ex.shutdown();\n             ex.shutdownNow();\n         }\n     }\n \n-    private void _testAll(Path[] testFiles, int numThreads, int numIterations,\n+    private void _testAll(Path[] testFiles, ParseContext[] parseContext, int numThreads, int numIterations,\n                           Map<Path, Extract> truth, ExecutorService ex) {\n \n         ExecutorCompletionService<Integer> executorCompletionService = new ExecutorCompletionService<>(ex);\n \n         //use the same parser in all threads\n         Parser parser = new AutoDetectParser();\n-        RecursiveParserWrapper wrapper = new RecursiveParserWrapper(parser,\n-                new BasicContentHandlerFactory(BasicContentHandlerFactory.HANDLER_TYPE.TEXT, -1));\n+        RecursiveParserWrapper wrapper = new RecursiveParserWrapper(parser);\n         for (int i = 0; i < numThreads; i++) {\n-            executorCompletionService.submit(new TikaRunner(wrapper, numIterations, testFiles, truth));\n+            executorCompletionService.submit(new TikaRunner(wrapper, parseContext[i], numIterations, testFiles, truth));\n         }\n \n         int completed = 0;\n@@ -155,20 +223,20 @@ private void _testAll(Path[] testFiles, int numThreads, int numIterations,\n                     future.get();//trigger exceptions from thread\n                     completed++;\n                 }\n-            } catch (InterruptedException|ExecutionException e) {\n+            } catch (InterruptedException | ExecutionException e) {\n                 throw new RuntimeException(e);\n             }\n         }\n     }\n \n-    private static Path[] getTestFiles(final FileFilter fileFilter) throws URISyntaxException, IOException {\n+    public static Path[] getTestFiles(final FileFilter fileFilter) throws URISyntaxException, IOException {\n         Path root = Paths.get(\n                 MultiThreadedTikaTest.class.getResource(\"/test-documents\").toURI());\n         final List<Path> files = new ArrayList<>();\n         Files.walkFileTree(root, new SimpleFileVisitor<Path>() {\n             @Override\n             public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException {\n-                if (fileFilter != null && ! fileFilter.accept(file.toFile())) {\n+                if (fileFilter != null && !fileFilter.accept(file.toFile())) {\n                     return FileVisitResult.CONTINUE;\n                 }\n                 if (!attrs.isDirectory()) {\n@@ -182,7 +250,23 @@ public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IO\n         return files.toArray(new Path[files.size()]);\n     }\n \n-    private static ConcurrentHashMap<Path, Extract> getBaseline(Path[] files) {\n+    private static ConcurrentHashMap<Path, MediaType> getBaselineDetection(Detector detector, Path[] files) {\n+\n+        ConcurrentHashMap<Path, MediaType> baseline = new ConcurrentHashMap<>();\n+        XmlRootExtractor extractor = new XmlRootExtractor();\n+        for (Path f : files) {\n+            Metadata metadata = new Metadata();\n+            try (TikaInputStream tis = TikaInputStream.get(f, metadata)) {\n+                baseline.put(f, detector.detect(tis, metadata));\n+                baseline.put(f, detector.detect(tis, metadata));\n+            } catch (IOException e) {\n+                e.printStackTrace();\n+            }\n+        }\n+        return baseline;\n+    }\n+\n+    private static ConcurrentHashMap<Path, Extract> getBaseline(Path[] files, ParseContext parseContext) {\n         ConcurrentHashMap<Path, Extract> baseline = new ConcurrentHashMap<>();\n         for (Path f : files) {\n \n@@ -192,8 +276,8 @@ private static ConcurrentHashMap<Path, Extract> getBaseline(Path[] files) {\n                 RecursiveParserWrapperHandler handler = new RecursiveParserWrapperHandler(\n                         new BasicContentHandlerFactory(BasicContentHandlerFactory.HANDLER_TYPE.TEXT, -1),\n                         -1);\n-                try (InputStream is = Files.newInputStream(f)) {\n-                    wrapper.parse(is, handler, new Metadata(), new ParseContext());\n+                try (TikaInputStream is = TikaInputStream.get(f)) {\n+                    wrapper.parse(is, handler, new Metadata(), parseContext);\n                 }\n                 List<Metadata> metadataList = handler.getMetadataList();\n                 baseline.put(f, new Extract(metadataList));\n@@ -204,32 +288,90 @@ private static ConcurrentHashMap<Path, Extract> getBaseline(Path[] files) {\n         return baseline;\n     }\n \n-    private static List<Metadata> getRecursiveMetadata(InputStream is, RecursiveParserWrapper wrapper) throws Exception {\n+    private static List<Metadata> getRecursiveMetadata(InputStream is,\n+                                                       RecursiveParserWrapper wrapper, ParseContext parseContext) throws Exception {\n         //different from parent TikaTest in that this extracts text.\n         //can't extract xhtml because \"tmp\" file names wind up in\n         //content's metadata and they'll differ by file.\n \n         RecursiveParserWrapperHandler handler = new RecursiveParserWrapperHandler(\n                 new BasicContentHandlerFactory(BasicContentHandlerFactory.HANDLER_TYPE.TEXT, -1),\n                 -1);\n-        wrapper.parse(is, handler, new Metadata(), new ParseContext());\n+        wrapper.parse(is, handler, new Metadata(), parseContext);\n         return handler.getMetadataList();\n     }\n \n+    private class SAXPoolResizer implements Callable<Integer> {\n+        private final int maxResize;\n+        private final Random rand = new Random();\n+        SAXPoolResizer(int maxResize) {\n+            this.maxResize = maxResize;\n+        }\n+\n+        public Integer call() throws TikaException  {\n+            int resized = 0;\n+            while (true) {\n+                try {\n+                    Thread.yield();\n+                    Thread.sleep(500);\n+                } catch (InterruptedException e) {\n+                    return resized;\n+                }\n+                if (maxResize > 0 && rand.nextFloat() > 0.01) {\n+                    int sz = rand.nextInt(maxResize)+1;\n+                    XMLReaderUtils.setPoolSize(sz);\n+                    resized++;\n+                }\n+            }\n+        }\n+    }\n+\n+    private class TikaDetectorRunner implements Callable<Integer> {\n+        private final Detector detector;\n+        private final int iterations;\n+        private final Path[] files;\n+        private final Map<Path, MediaType> truth;\n+        private final Random random = new Random();\n+\n+        private TikaDetectorRunner(Detector detector, int iterations, Path[] files, Map<Path, MediaType> truth) {\n+            this.detector = detector;\n+            this.iterations = iterations;\n+            this.files = files;\n+            this.truth = truth;\n+        }\n+\n+        @Override\n+        public Integer call() throws Exception {\n+            for (int i = 0; i < iterations; i++) {\n+                int randIndex = random.nextInt(files.length);\n+                Path testFile = files[randIndex];\n+                Metadata metadata = new Metadata();\n+                try (TikaInputStream tis = TikaInputStream.get(testFile, metadata)) {\n+                    MediaType mediaType = detector.detect(tis, metadata);\n+                    assertEquals(\"failed on: \" + testFile.getFileName(), truth.get(testFile), mediaType);\n+                }\n+            }\n+            return 1;\n+        }\n+\n+    }\n+\n+\n     //TODO: make this return something useful besides an integer\n     private class TikaRunner implements Callable<Integer> {\n         private final RecursiveParserWrapper parser;\n         private final int iterations;\n         private final Path[] files;\n         private final Map<Path, Extract> truth;\n-\n+        private final ParseContext parseContext;\n         private final Random random = new Random();\n \n-        private TikaRunner(RecursiveParserWrapper parser, int iterations, Path[] files, Map<Path, Extract> truth) {\n+        private TikaRunner(RecursiveParserWrapper parser, ParseContext parseContext, int iterations, Path[] files, Map<Path, Extract> truth) {\n             this.parser = parser;\n             this.iterations = iterations;\n             this.files = files;\n             this.truth = truth;\n+            this.parseContext = parseContext;\n         }\n \n         @Override\n@@ -238,10 +380,10 @@ public Integer call() throws Exception {\n                 int randIndex = random.nextInt(files.length);\n                 Path testFile = files[randIndex];\n                 try (InputStream is = Files.newInputStream(testFile)) {\n-                    List<Metadata> metadataList = getRecursiveMetadata(is, parser);\n+                    List<Metadata> metadataList = getRecursiveMetadata(is, parser, parseContext);\n                     assertExtractEquals(truth.get(testFile), new Extract(metadataList));\n                 } catch (Exception e) {\n-                    throw new RuntimeException(testFile+\" triggered this exception\", e);\n+                    throw new RuntimeException(testFile + \" triggered this exception\", e);\n                 }\n             }\n             return 1;"
        },
        {
            "sha": "0cfa62185a8b7c36b3a46d49c392517532be1d00",
            "filename": "tika-parsers/pom.xml",
            "status": "modified",
            "additions": 6,
            "deletions": 1,
            "changes": 7,
            "blob_url": "https://github.com/apache/tika/blob/4b38d6228f4ba5ee912735dc692275499bbf45f6/tika-parsers%2Fpom.xml",
            "raw_url": "https://github.com/apache/tika/raw/4b38d6228f4ba5ee912735dc692275499bbf45f6/tika-parsers%2Fpom.xml",
            "contents_url": "https://api.github.com/repos/apache/tika/contents/tika-parsers%2Fpom.xml?ref=4b38d6228f4ba5ee912735dc692275499bbf45f6",
            "patch": "@@ -739,7 +739,12 @@\n         </exclusion>\n       </exclusions>\n     </dependency>\n-\n+    <dependency>\n+      <groupId>org.apache.commons</groupId>\n+      <artifactId>commons-math3</artifactId>\n+      <version>3.6.1</version>\n+      <scope>test</scope>\n+    </dependency>\n   </dependencies>\n   <build>\n     <plugins>"
        },
        {
            "sha": "e359fbcc32b59640229c25cdb30ac3202190dd41",
            "filename": "tika-parsers/src/test/java/org/apache/tika/TestParsers.java",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/apache/tika/blob/4b38d6228f4ba5ee912735dc692275499bbf45f6/tika-parsers%2Fsrc%2Ftest%2Fjava%2Forg%2Fapache%2Ftika%2FTestParsers.java",
            "raw_url": "https://github.com/apache/tika/raw/4b38d6228f4ba5ee912735dc692275499bbf45f6/tika-parsers%2Fsrc%2Ftest%2Fjava%2Forg%2Fapache%2Ftika%2FTestParsers.java",
            "contents_url": "https://api.github.com/repos/apache/tika/contents/tika-parsers%2Fsrc%2Ftest%2Fjava%2Forg%2Fapache%2Ftika%2FTestParsers.java?ref=4b38d6228f4ba5ee912735dc692275499bbf45f6",
            "patch": "@@ -113,6 +113,6 @@ public void testComment() throws Exception {\n     @Ignore(\"ignore for regular builds; run occasionally\")\n     public void testAllMultiThreaded() throws Exception {\n         //this runs against all files in /test-documents\n-        testMultiThreaded(10, 100, null);\n+        //testMultiThreaded(10, 100, null);\n     }\n }"
        },
        {
            "sha": "b5198b1ef40f9739bf5cb22861dba2fa4bff394f",
            "filename": "tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java",
            "status": "modified",
            "additions": 37,
            "deletions": 1,
            "changes": 38,
            "blob_url": "https://github.com/apache/tika/blob/4b38d6228f4ba5ee912735dc692275499bbf45f6/tika-parsers%2Fsrc%2Ftest%2Fjava%2Forg%2Fapache%2Ftika%2Fdetect%2FTestContainerAwareDetector.java",
            "raw_url": "https://github.com/apache/tika/raw/4b38d6228f4ba5ee912735dc692275499bbf45f6/tika-parsers%2Fsrc%2Ftest%2Fjava%2Forg%2Fapache%2Ftika%2Fdetect%2FTestContainerAwareDetector.java",
            "contents_url": "https://api.github.com/repos/apache/tika/contents/tika-parsers%2Fsrc%2Ftest%2Fjava%2Forg%2Fapache%2Ftika%2Fdetect%2FTestContainerAwareDetector.java?ref=4b38d6228f4ba5ee912735dc692275499bbf45f6",
            "patch": "@@ -21,24 +21,29 @@\n import static org.junit.Assert.assertTrue;\n \n import java.io.File;\n+import java.io.FileFilter;\n import java.io.FilenameFilter;\n import java.io.IOException;\n import java.io.InputStream;\n+import java.nio.file.Path;\n \n import org.apache.poi.poifs.filesystem.NPOIFSFileSystem;\n+import org.apache.tika.MultiThreadedTikaTest;\n+import org.apache.tika.Tika;\n import org.apache.tika.config.TikaConfig;\n import org.apache.tika.io.TikaInputStream;\n import org.apache.tika.metadata.Metadata;\n import org.apache.tika.metadata.TikaCoreProperties;\n import org.apache.tika.mime.MediaType;\n import org.apache.tika.mime.MimeTypes;\n import org.apache.tika.parser.iwork.iwana.IWork13PackageParser;\n+import org.apache.tika.utils.XMLReaderUtils;\n import org.junit.Test;\n \n /**\n  * Junit test class for {@link ContainerAwareDetector}\n  */\n-public class TestContainerAwareDetector {\n+public class TestContainerAwareDetector extends MultiThreadedTikaTest {\n     private final TikaConfig tikaConfig = TikaConfig.getDefaultConfig();\n     private final MimeTypes mimeTypes = tikaConfig.getMimeRepository();\n     private final Detector detector = new DefaultDetector(mimeTypes);\n@@ -436,4 +441,35 @@ public void testTruncatedFiles() throws Exception {\n         }\n    }\n \n+    @Test\n+    public void testXMLMultiThreaded() throws Exception {\n+        Detector detector = new Tika().getDetector();\n+        FileFilter filter = new FileFilter() {\n+            @Override\n+            public boolean accept(File pathname) {\n+                if (pathname.getName().endsWith(\".xml\")) {\n+                    return true;\n+                }\n+                return false;\n+            }\n+        };\n+        int numThreads = 1;\n+        XMLReaderUtils.setPoolSize(numThreads);\n+        testDetector(detector, numThreads, 20, filter, numThreads*2);\n+    }\n+\n+    @Test\n+    public void testAllMultithreaded() throws Exception {\n+        Detector detector = new Tika().getDetector();\n+        FileFilter filter = new FileFilter() {\n+            @Override\n+            public boolean accept(File pathname) {\n+                    return true;\n+            }\n+        };\n+        int numThreads = 20;\n+        XMLReaderUtils.setPoolSize(numThreads);\n+        testDetector(detector, numThreads, 50, filter, numThreads*3);\n+    }\n+\n }"
        },
        {
            "sha": "3129453dc6528549789818ec79d7691fbdadb42f",
            "filename": "tika-parsers/src/test/java/org/apache/tika/parser/chm/TestChmExtraction.java",
            "status": "modified",
            "additions": 5,
            "deletions": 1,
            "changes": 6,
            "blob_url": "https://github.com/apache/tika/blob/4b38d6228f4ba5ee912735dc692275499bbf45f6/tika-parsers%2Fsrc%2Ftest%2Fjava%2Forg%2Fapache%2Ftika%2Fparser%2Fchm%2FTestChmExtraction.java",
            "raw_url": "https://github.com/apache/tika/raw/4b38d6228f4ba5ee912735dc692275499bbf45f6/tika-parsers%2Fsrc%2Ftest%2Fjava%2Forg%2Fapache%2Ftika%2Fparser%2Fchm%2FTestChmExtraction.java",
            "contents_url": "https://api.github.com/repos/apache/tika/contents/tika-parsers%2Fsrc%2Ftest%2Fjava%2Forg%2Fapache%2Ftika%2Fparser%2Fchm%2FTestChmExtraction.java?ref=4b38d6228f4ba5ee912735dc692275499bbf45f6",
            "patch": "@@ -214,7 +214,11 @@ public void testOOM() throws Exception {\n \n     @Test\n     public void testMultiThreaded() throws Exception {\n-        testMultiThreaded(10, 10, new FileFilter() {\n+        ParseContext[] parseContexts = new ParseContext[10];\n+        for (int i = 0; i < parseContexts.length; i++) {\n+            parseContexts[i] = new ParseContext();\n+        }\n+        testMultiThreaded(parseContexts, 10, 10, new FileFilter() {\n                     @Override\n                     public boolean accept(File pathname) {\n                         if (pathname.getName().toLowerCase(Locale.ENGLISH).endsWith(\".chm\")) {"
        }
    ]
}