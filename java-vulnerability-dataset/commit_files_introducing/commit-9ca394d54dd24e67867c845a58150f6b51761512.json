{
    "sha": "9ca394d54dd24e67867c845a58150f6b51761512",
    "node_id": "MDY6Q29tbWl0MjM0MTg1MTc6OWNhMzk0ZDU0ZGQyNGU2Nzg2N2M4NDVhNTgxNTBmNmI1MTc2MTUxMg==",
    "commit": {
        "author": {
            "name": "Christopher Douglas",
            "email": "cdouglas@apache.org",
            "date": "2013-12-17T22:54:31Z"
        },
        "committer": {
            "name": "Christopher Douglas",
            "email": "cdouglas@apache.org",
            "date": "2013-12-17T22:54:31Z"
        },
        "message": "MAPREDUCE-5189. Add policies and wiring to respond to preemption requests\nfrom YARN. Contributed by Carlo Curino.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1551748 13f79535-47bb-0310-9956-ffa450edef68",
        "tree": {
            "sha": "b0c9c9817653f36d13c64ee00c4f8bddfea7addf",
            "url": "https://api.github.com/repos/apache/hadoop/git/trees/b0c9c9817653f36d13c64ee00c4f8bddfea7addf"
        },
        "url": "https://api.github.com/repos/apache/hadoop/git/commits/9ca394d54dd24e67867c845a58150f6b51761512",
        "comment_count": 0,
        "verification": {
            "verified": false,
            "reason": "unsigned",
            "signature": null,
            "payload": null,
            "verified_at": null
        }
    },
    "url": "https://api.github.com/repos/apache/hadoop/commits/9ca394d54dd24e67867c845a58150f6b51761512",
    "html_url": "https://github.com/apache/hadoop/commit/9ca394d54dd24e67867c845a58150f6b51761512",
    "comments_url": "https://api.github.com/repos/apache/hadoop/commits/9ca394d54dd24e67867c845a58150f6b51761512/comments",
    "author": {
        "login": "cdouglas",
        "id": 145508,
        "node_id": "MDQ6VXNlcjE0NTUwOA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/145508?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/cdouglas",
        "html_url": "https://github.com/cdouglas",
        "followers_url": "https://api.github.com/users/cdouglas/followers",
        "following_url": "https://api.github.com/users/cdouglas/following{/other_user}",
        "gists_url": "https://api.github.com/users/cdouglas/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/cdouglas/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/cdouglas/subscriptions",
        "organizations_url": "https://api.github.com/users/cdouglas/orgs",
        "repos_url": "https://api.github.com/users/cdouglas/repos",
        "events_url": "https://api.github.com/users/cdouglas/events{/privacy}",
        "received_events_url": "https://api.github.com/users/cdouglas/received_events",
        "type": "User",
        "user_view_type": "public",
        "site_admin": false
    },
    "committer": {
        "login": "cdouglas",
        "id": 145508,
        "node_id": "MDQ6VXNlcjE0NTUwOA==",
        "avatar_url": "https://avatars.githubusercontent.com/u/145508?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/cdouglas",
        "html_url": "https://github.com/cdouglas",
        "followers_url": "https://api.github.com/users/cdouglas/followers",
        "following_url": "https://api.github.com/users/cdouglas/following{/other_user}",
        "gists_url": "https://api.github.com/users/cdouglas/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/cdouglas/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/cdouglas/subscriptions",
        "organizations_url": "https://api.github.com/users/cdouglas/orgs",
        "repos_url": "https://api.github.com/users/cdouglas/repos",
        "events_url": "https://api.github.com/users/cdouglas/events{/privacy}",
        "received_events_url": "https://api.github.com/users/cdouglas/received_events",
        "type": "User",
        "user_view_type": "public",
        "site_admin": false
    },
    "parents": [
        {
            "sha": "ca125153b319a8f5d75585d25cb0f37ae717be01",
            "url": "https://api.github.com/repos/apache/hadoop/commits/ca125153b319a8f5d75585d25cb0f37ae717be01",
            "html_url": "https://github.com/apache/hadoop/commit/ca125153b319a8f5d75585d25cb0f37ae717be01"
        }
    ],
    "stats": {
        "total": 600,
        "additions": 575,
        "deletions": 25
    },
    "files": [
        {
            "sha": "63daf66a3ec130cebb82e1ec70efdec71514b83e",
            "filename": "hadoop-mapreduce-project/CHANGES.txt",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/apache/hadoop/blob/9ca394d54dd24e67867c845a58150f6b51761512/hadoop-mapreduce-project%2FCHANGES.txt",
            "raw_url": "https://github.com/apache/hadoop/raw/9ca394d54dd24e67867c845a58150f6b51761512/hadoop-mapreduce-project%2FCHANGES.txt",
            "contents_url": "https://api.github.com/repos/apache/hadoop/contents/hadoop-mapreduce-project%2FCHANGES.txt?ref=9ca394d54dd24e67867c845a58150f6b51761512",
            "patch": "@@ -74,6 +74,9 @@ Trunk (Unreleased)\n     MAPREDUCE-5197. Add a service for checkpointing task state.\n     (Carlo Curino via cdouglas)\n \n+    MAPREDUCE-5189. Add policies and wiring to respond to preemption requests\n+    from YARN. (Carlo Curino via cdouglas)\n+\n   BUG FIXES\n \n     MAPREDUCE-4272. SortedRanges.Range#compareTo is not spec compliant."
        },
        {
            "sha": "8af7e3798738b9f2fd7b519d549b783f42eca72c",
            "filename": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/TaskAttemptListenerImpl.java",
            "status": "modified",
            "additions": 5,
            "deletions": 1,
            "changes": 6,
            "blob_url": "https://github.com/apache/hadoop/blob/9ca394d54dd24e67867c845a58150f6b51761512/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-app%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapred%2FTaskAttemptListenerImpl.java",
            "raw_url": "https://github.com/apache/hadoop/raw/9ca394d54dd24e67867c845a58150f6b51761512/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-app%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapred%2FTaskAttemptListenerImpl.java",
            "contents_url": "https://api.github.com/repos/apache/hadoop/contents/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-app%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapred%2FTaskAttemptListenerImpl.java?ref=9ca394d54dd24e67867c845a58150f6b51761512",
            "patch": "@@ -48,6 +48,7 @@\n import org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptStatusUpdateEvent;\n import org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptStatusUpdateEvent.TaskAttemptStatus;\n import org.apache.hadoop.mapreduce.v2.app.rm.RMHeartbeatHandler;\n+import org.apache.hadoop.mapreduce.v2.app.rm.preemption.AMPreemptionPolicy;\n import org.apache.hadoop.mapreduce.v2.app.security.authorize.MRAMPolicyProvider;\n import org.apache.hadoop.net.NetUtils;\n import org.apache.hadoop.security.authorize.PolicyProvider;\n@@ -84,14 +85,17 @@ public class TaskAttemptListenerImpl extends CompositeService\n       .newSetFromMap(new ConcurrentHashMap<WrappedJvmID, Boolean>()); \n   \n   private JobTokenSecretManager jobTokenSecretManager = null;\n+  private AMPreemptionPolicy preemptionPolicy;\n   \n   public TaskAttemptListenerImpl(AppContext context,\n       JobTokenSecretManager jobTokenSecretManager,\n-      RMHeartbeatHandler rmHeartbeatHandler) {\n+      RMHeartbeatHandler rmHeartbeatHandler,\n+      AMPreemptionPolicy preemptionPolicy) {\n     super(TaskAttemptListenerImpl.class.getName());\n     this.context = context;\n     this.jobTokenSecretManager = jobTokenSecretManager;\n     this.rmHeartbeatHandler = rmHeartbeatHandler;\n+    this.preemptionPolicy = preemptionPolicy;\n   }\n \n   @Override"
        },
        {
            "sha": "ca6aadfb1cce0713ec7f075a76045bebde20a2e3",
            "filename": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/MRAppMaster.java",
            "status": "modified",
            "additions": 20,
            "deletions": 6,
            "changes": 26,
            "blob_url": "https://github.com/apache/hadoop/blob/9ca394d54dd24e67867c845a58150f6b51761512/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-app%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapreduce%2Fv2%2Fapp%2FMRAppMaster.java",
            "raw_url": "https://github.com/apache/hadoop/raw/9ca394d54dd24e67867c845a58150f6b51761512/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-app%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapreduce%2Fv2%2Fapp%2FMRAppMaster.java",
            "contents_url": "https://api.github.com/repos/apache/hadoop/contents/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-app%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapreduce%2Fv2%2Fapp%2FMRAppMaster.java?ref=9ca394d54dd24e67867c845a58150f6b51761512",
            "patch": "@@ -102,6 +102,8 @@\n import org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator;\n import org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor;\n import org.apache.hadoop.mapreduce.v2.app.rm.RMHeartbeatHandler;\n+import org.apache.hadoop.mapreduce.v2.app.rm.preemption.AMPreemptionPolicy;\n+import org.apache.hadoop.mapreduce.v2.app.rm.preemption.NoopAMPreemptionPolicy;\n import org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator;\n import org.apache.hadoop.mapreduce.v2.app.speculate.Speculator;\n import org.apache.hadoop.mapreduce.v2.app.speculate.SpeculatorEvent;\n@@ -188,15 +190,16 @@ public class MRAppMaster extends CompositeService {\n   private ContainerLauncher containerLauncher;\n   private EventHandler<CommitterEvent> committerEventHandler;\n   private Speculator speculator;\n-  private TaskAttemptListener taskAttemptListener;\n-  private JobTokenSecretManager jobTokenSecretManager =\n+  protected TaskAttemptListener taskAttemptListener;\n+  protected JobTokenSecretManager jobTokenSecretManager =\n       new JobTokenSecretManager();\n   private JobId jobId;\n   private boolean newApiCommitter;\n   private OutputCommitter committer;\n   private JobEventDispatcher jobEventDispatcher;\n   private JobHistoryEventHandler jobHistoryEventHandler;\n   private SpeculatorEventDispatcher speculatorEventDispatcher;\n+  private AMPreemptionPolicy preemptionPolicy;\n \n   private Job job;\n   private Credentials jobCredentials = new Credentials(); // Filled during init\n@@ -383,8 +386,12 @@ protected void serviceInit(final Configuration conf) throws Exception {\n       committerEventHandler = createCommitterEventHandler(context, committer);\n       addIfService(committerEventHandler);\n \n+      //policy handling preemption requests from RM\n+      preemptionPolicy = createPreemptionPolicy(conf);\n+      preemptionPolicy.init(context);\n+\n       //service to handle requests to TaskUmbilicalProtocol\n-      taskAttemptListener = createTaskAttemptListener(context);\n+      taskAttemptListener = createTaskAttemptListener(context, preemptionPolicy);\n       addIfService(taskAttemptListener);\n \n       //service to log job history events\n@@ -475,6 +482,12 @@ private OutputCommitter createOutputCommitter(Configuration conf) {\n     return committer;\n   }\n \n+  protected AMPreemptionPolicy createPreemptionPolicy(Configuration conf) {\n+    return ReflectionUtils.newInstance(conf.getClass(\n+          MRJobConfig.MR_AM_PREEMPTION_POLICY,\n+          NoopAMPreemptionPolicy.class, AMPreemptionPolicy.class), conf);\n+  }\n+\n   protected boolean keepJobFiles(JobConf conf) {\n     return (conf.getKeepTaskFilesPattern() != null || conf\n         .getKeepFailedTaskFiles());\n@@ -692,10 +705,11 @@ protected Speculator createSpeculator(Configuration conf, AppContext context) {\n     }\n   }\n \n-  protected TaskAttemptListener createTaskAttemptListener(AppContext context) {\n+  protected TaskAttemptListener createTaskAttemptListener(AppContext context,\n+      AMPreemptionPolicy preemptionPolicy) {\n     TaskAttemptListener lis =\n         new TaskAttemptListenerImpl(context, jobTokenSecretManager,\n-            getRMHeartbeatHandler());\n+            getRMHeartbeatHandler(), preemptionPolicy);\n     return lis;\n   }\n \n@@ -805,7 +819,7 @@ protected void serviceStart() throws Exception {\n             , containerID);\n       } else {\n         this.containerAllocator = new RMContainerAllocator(\n-            this.clientService, this.context);\n+            this.clientService, this.context, preemptionPolicy);\n       }\n       ((Service)this.containerAllocator).init(getConfig());\n       ((Service)this.containerAllocator).start();"
        },
        {
            "sha": "dd739f2b7c3dfbbb5536701f724d65839a1ca4e2",
            "filename": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java",
            "status": "modified",
            "additions": 47,
            "deletions": 4,
            "changes": 51,
            "blob_url": "https://github.com/apache/hadoop/blob/9ca394d54dd24e67867c845a58150f6b51761512/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-app%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapreduce%2Fv2%2Fapp%2Frm%2FRMContainerAllocator.java",
            "raw_url": "https://github.com/apache/hadoop/raw/9ca394d54dd24e67867c845a58150f6b51761512/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-app%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapreduce%2Fv2%2Fapp%2Frm%2FRMContainerAllocator.java",
            "contents_url": "https://api.github.com/repos/apache/hadoop/contents/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-app%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapreduce%2Fv2%2Fapp%2Frm%2FRMContainerAllocator.java?ref=9ca394d54dd24e67867c845a58150f6b51761512",
            "patch": "@@ -57,6 +57,7 @@\n import org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptEvent;\n import org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptEventType;\n import org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptKillEvent;\n+import org.apache.hadoop.mapreduce.v2.app.rm.preemption.AMPreemptionPolicy;\n import org.apache.hadoop.util.StringInterner;\n import org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse;\n import org.apache.hadoop.yarn.api.records.Container;\n@@ -67,6 +68,7 @@\n import org.apache.hadoop.yarn.api.records.NodeId;\n import org.apache.hadoop.yarn.api.records.NodeReport;\n import org.apache.hadoop.yarn.api.records.NodeState;\n+import org.apache.hadoop.yarn.api.records.PreemptionMessage;\n import org.apache.hadoop.yarn.api.records.Priority;\n import org.apache.hadoop.yarn.client.api.NMTokenCache;\n import org.apache.hadoop.yarn.exceptions.YarnRuntimeException;\n@@ -147,13 +149,17 @@ added to the pending and are ramped up (added to scheduled) based\n   private long retryInterval;\n   private long retrystartTime;\n \n+  private final AMPreemptionPolicy preemptionPolicy;\n+\n   BlockingQueue<ContainerAllocatorEvent> eventQueue\n     = new LinkedBlockingQueue<ContainerAllocatorEvent>();\n \n   private ScheduleStats scheduleStats = new ScheduleStats();\n \n-  public RMContainerAllocator(ClientService clientService, AppContext context) {\n+  public RMContainerAllocator(ClientService clientService, AppContext context,\n+      AMPreemptionPolicy preemptionPolicy) {\n     super(clientService, context);\n+    this.preemptionPolicy = preemptionPolicy;\n     this.stopped = new AtomicBoolean(false);\n   }\n \n@@ -361,11 +367,15 @@ protected synchronized void handleEvent(ContainerAllocatorEvent event) {\n         LOG.error(\"Could not deallocate container for task attemptId \" + \n             aId);\n       }\n+      preemptionPolicy.handleCompletedContainer(event.getAttemptID());\n     } else if (\n         event.getType() == ContainerAllocator.EventType.CONTAINER_FAILED) {\n       ContainerFailedEvent fEv = (ContainerFailedEvent) event;\n       String host = getHost(fEv.getContMgrAddress());\n       containerFailedOnHost(host);\n+      // propagate failures to preemption policy to discard checkpoints for\n+      // failed tasks\n+      preemptionPolicy.handleFailedContainer(event.getAttemptID());\n     }\n   }\n \n@@ -399,7 +409,7 @@ private void preemptReducesIfNeeded() {\n         }\n         scheduledRequests.reduces.clear();\n         \n-        //preempt for making space for atleast one map\n+        //preempt for making space for at least one map\n         int premeptionLimit = Math.max(mapResourceReqt, \n             (int) (maxReducePreemptionLimit * memLimit));\n         \n@@ -409,7 +419,7 @@ private void preemptReducesIfNeeded() {\n         int toPreempt = (int) Math.ceil((float) preemptMem/reduceResourceReqt);\n         toPreempt = Math.min(toPreempt, assignedRequests.reduces.size());\n         \n-        LOG.info(\"Going to preempt \" + toPreempt);\n+        LOG.info(\"Going to preempt \" + toPreempt + \" due to lack of space for maps\");\n         assignedRequests.preemptReduce(toPreempt);\n       }\n     }\n@@ -595,6 +605,14 @@ private List<Container> getResources() throws Exception {\n     }\n     \n     List<ContainerStatus> finishedContainers = response.getCompletedContainersStatuses();\n+\n+    // propagate preemption requests\n+    final PreemptionMessage preemptReq = response.getPreemptionMessage();\n+    if (preemptReq != null) {\n+      preemptionPolicy.preempt(\n+          new PreemptionContext(assignedRequests), preemptReq);\n+    }\n+\n     if (newContainers.size() + finishedContainers.size() > 0 || headRoom != newHeadRoom) {\n       //something changed\n       recalculateReduceSchedule = true;\n@@ -630,7 +648,9 @@ private List<Container> getResources() throws Exception {\n         String diagnostics = StringInterner.weakIntern(cont.getDiagnostics());\n         eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n             diagnostics));\n-      }      \n+\n+        preemptionPolicy.handleCompletedContainer(attemptID);\n+      }\n     }\n     return newContainers;\n   }\n@@ -1232,4 +1252,27 @@ public void log(String msgPrefix) {\n         \" RackLocal:\" + rackLocalAssigned);\n     }\n   }\n+\n+  static class PreemptionContext extends AMPreemptionPolicy.Context {\n+    final AssignedRequests reqs;\n+\n+    PreemptionContext(AssignedRequests reqs) {\n+      this.reqs = reqs;\n+    }\n+    @Override\n+    public TaskAttemptId getTaskAttempt(ContainerId container) {\n+      return reqs.get(container);\n+    }\n+\n+    @Override\n+    public List<Container> getContainers(TaskType t){\n+      if(TaskType.REDUCE.equals(t))\n+        return new ArrayList<Container>(reqs.reduces.values());\n+      if(TaskType.MAP.equals(t))\n+        return new ArrayList<Container>(reqs.maps.values());\n+      return null;\n+    }\n+\n+  }\n+\n }"
        },
        {
            "sha": "0bbe75bdea379203c101cbdd8c04bba8e510eda6",
            "filename": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/preemption/AMPreemptionPolicy.java",
            "status": "added",
            "additions": 117,
            "deletions": 0,
            "changes": 117,
            "blob_url": "https://github.com/apache/hadoop/blob/9ca394d54dd24e67867c845a58150f6b51761512/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-app%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapreduce%2Fv2%2Fapp%2Frm%2Fpreemption%2FAMPreemptionPolicy.java",
            "raw_url": "https://github.com/apache/hadoop/raw/9ca394d54dd24e67867c845a58150f6b51761512/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-app%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapreduce%2Fv2%2Fapp%2Frm%2Fpreemption%2FAMPreemptionPolicy.java",
            "contents_url": "https://api.github.com/repos/apache/hadoop/contents/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-app%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapreduce%2Fv2%2Fapp%2Frm%2Fpreemption%2FAMPreemptionPolicy.java?ref=9ca394d54dd24e67867c845a58150f6b51761512",
            "patch": "@@ -0,0 +1,117 @@\n+/**\n+* Licensed to the Apache Software Foundation (ASF) under one\n+* or more contributor license agreements.  See the NOTICE file\n+* distributed with this work for additional information\n+* regarding copyright ownership.  The ASF licenses this file\n+* to you under the Apache License, Version 2.0 (the\n+* \"License\"); you may not use this file except in compliance\n+* with the License.  You may obtain a copy of the License at\n+*\n+*     http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+package org.apache.hadoop.mapreduce.v2.app.rm.preemption;\n+\n+import java.util.List;\n+\n+import org.apache.hadoop.mapred.TaskAttemptID;\n+import org.apache.hadoop.mapred.TaskID;\n+import org.apache.hadoop.mapreduce.checkpoint.TaskCheckpointID;\n+import org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId;\n+import org.apache.hadoop.mapreduce.v2.api.records.TaskType;\n+import org.apache.hadoop.mapreduce.v2.app.AppContext;\n+import org.apache.hadoop.yarn.api.records.Container;\n+import org.apache.hadoop.yarn.api.records.ContainerId;\n+import org.apache.hadoop.yarn.api.records.PreemptionMessage;\n+\n+/**\n+ * Policy encoding the {@link org.apache.hadoop.mapreduce.v2.app.MRAppMaster}\n+ * response to preemption requests from the ResourceManager.\n+ * @see org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator\n+ */\n+public interface AMPreemptionPolicy {\n+\n+  public abstract class Context {\n+\n+    /**\n+     * @param container ID of container to preempt\n+     * @return Task associated with the running container or <code>null</code>\n+     * if no task is bound to that container.\n+     */\n+    public abstract TaskAttemptId getTaskAttempt(ContainerId container);\n+\n+    /**\n+     * Method provides the complete list of containers running task of type t\n+     * for this AM.\n+     * @param t the type of containers\n+     * @return a map containing\n+     */\n+    public abstract List<Container> getContainers(TaskType t);\n+\n+  }\n+\n+  public void init(AppContext context);\n+\n+  /**\n+   * Callback informing the policy of ResourceManager. requests for resources\n+   * to return to the cluster. The policy may take arbitrary action to satisfy\n+   * requests by checkpointing task state, returning containers, or ignoring\n+   * requests. The RM may elect to enforce these requests by forcibly killing\n+   * containers not returned after some duration.\n+   * @param context Handle to the current state of running containers\n+   * @param preemptionRequests Request from RM for resources to return.\n+   */\n+  public void preempt(Context context, PreemptionMessage preemptionRequests);\n+\n+  /**\n+   * This method is invoked by components interested to learn whether a certain\n+   * task is being preempted.\n+   * @param attemptID Task attempt to query\n+   * @return true if this attempt is being preempted\n+   */\n+  public boolean isPreempted(TaskAttemptId attemptID);\n+\n+  /**\n+   * This method is used to report to the policy that a certain task has been\n+   * successfully preempted (for bookeeping, counters, etc..)\n+   * @param attemptID Task attempt that preempted\n+   */\n+  public void reportSuccessfulPreemption(TaskAttemptID attemptID);\n+\n+  /**\n+   * Callback informing the policy of containers exiting with a failure. This\n+   * allows the policy to implemnt cleanup/compensating actions.\n+   * @param attemptID Task attempt that failed\n+   */\n+  public void handleFailedContainer(TaskAttemptId attemptID);\n+\n+  /**\n+   * Callback informing the policy of containers exiting cleanly. This is\n+   * reported to the policy for bookeeping purposes.\n+   * @param attemptID Task attempt that completed\n+   */\n+  public void handleCompletedContainer(TaskAttemptId attemptID);\n+\n+  /**\n+   * Method to retrieve the latest checkpoint for a given {@link TaskID}\n+   * @param taskId TaskID\n+   * @return CheckpointID associated with this task or null\n+   */\n+  public TaskCheckpointID getCheckpointID(TaskID taskId);\n+\n+  /**\n+   * Method to store the latest {@link\n+   * org.apache.hadoop.mapreduce.checkpoint.CheckpointID} for a given {@link\n+   * TaskID}. Assigning a null is akin to remove all previous checkpoints for\n+   * this task.\n+   * @param taskId TaskID\n+   * @param cid Checkpoint to assign or <tt>null</tt> to remove it.\n+   */\n+  public void setCheckpointID(TaskID taskId, TaskCheckpointID cid);\n+\n+}"
        },
        {
            "sha": "100ef4f7af4ec68c86119a1ddb6298bcf38dcbeb",
            "filename": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/preemption/KillAMPreemptionPolicy.java",
            "status": "added",
            "additions": 111,
            "deletions": 0,
            "changes": 111,
            "blob_url": "https://github.com/apache/hadoop/blob/9ca394d54dd24e67867c845a58150f6b51761512/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-app%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapreduce%2Fv2%2Fapp%2Frm%2Fpreemption%2FKillAMPreemptionPolicy.java",
            "raw_url": "https://github.com/apache/hadoop/raw/9ca394d54dd24e67867c845a58150f6b51761512/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-app%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapreduce%2Fv2%2Fapp%2Frm%2Fpreemption%2FKillAMPreemptionPolicy.java",
            "contents_url": "https://api.github.com/repos/apache/hadoop/contents/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-app%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapreduce%2Fv2%2Fapp%2Frm%2Fpreemption%2FKillAMPreemptionPolicy.java?ref=9ca394d54dd24e67867c845a58150f6b51761512",
            "patch": "@@ -0,0 +1,111 @@\n+/**\n+* Licensed to the Apache Software Foundation (ASF) under one\n+* or more contributor license agreements.  See the NOTICE file\n+* distributed with this work for additional information\n+* regarding copyright ownership.  The ASF licenses this file\n+* to you under the Apache License, Version 2.0 (the\n+* \"License\"); you may not use this file except in compliance\n+* with the License.  You may obtain a copy of the License at\n+*\n+*     http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+package org.apache.hadoop.mapreduce.v2.app.rm.preemption;\n+\n+import org.apache.commons.logging.Log;\n+import org.apache.commons.logging.LogFactory;\n+import org.apache.hadoop.mapred.TaskAttemptID;\n+import org.apache.hadoop.mapred.TaskID;\n+import org.apache.hadoop.mapreduce.JobCounter;\n+import org.apache.hadoop.mapreduce.checkpoint.TaskCheckpointID;\n+import org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId;\n+import org.apache.hadoop.mapreduce.v2.app.AppContext;\n+import org.apache.hadoop.mapreduce.v2.app.job.event.JobCounterUpdateEvent;\n+import org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptEvent;\n+import org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptEventType;\n+import org.apache.hadoop.yarn.api.records.ContainerId;\n+import org.apache.hadoop.yarn.api.records.PreemptionContainer;\n+import org.apache.hadoop.yarn.api.records.PreemptionMessage;\n+import org.apache.hadoop.yarn.event.EventHandler;\n+\n+/**\n+ * Sample policy that aggressively kills tasks when requested.\n+ */\n+public class KillAMPreemptionPolicy implements AMPreemptionPolicy {\n+\n+  private static final Log LOG =\n+      LogFactory.getLog(KillAMPreemptionPolicy.class);\n+\n+  @SuppressWarnings(\"rawtypes\")\n+  private EventHandler dispatcher = null;\n+\n+  @Override\n+  public void init(AppContext context) {\n+    dispatcher = context.getEventHandler();\n+  }\n+\n+  @Override\n+  public void preempt(Context ctxt, PreemptionMessage preemptionRequests) {\n+    // for both strict and negotiable preemption requests kill the\n+    // container\n+    for (PreemptionContainer c :\n+        preemptionRequests.getStrictContract().getContainers()) {\n+      killContainer(ctxt, c);\n+    }\n+    for (PreemptionContainer c :\n+         preemptionRequests.getContract().getContainers()) {\n+       killContainer(ctxt, c);\n+    }\n+  }\n+\n+  @SuppressWarnings(\"unchecked\")\n+  private void killContainer(Context ctxt, PreemptionContainer c){\n+    ContainerId reqCont = c.getId();\n+    TaskAttemptId reqTask = ctxt.getTaskAttempt(reqCont);\n+    LOG.info(\"Evicting \" + reqTask);\n+    dispatcher.handle(new TaskAttemptEvent(reqTask,\n+        TaskAttemptEventType.TA_KILL));\n+\n+    // add preemption to counters\n+    JobCounterUpdateEvent jce = new JobCounterUpdateEvent(reqTask\n+            .getTaskId().getJobId());\n+        jce.addCounterUpdate(JobCounter.TASKS_REQ_PREEMPT, 1);\n+        dispatcher.handle(jce);\n+  }\n+\n+  @Override\n+  public void handleFailedContainer(TaskAttemptId attemptID) {\n+    // ignore\n+  }\n+\n+  @Override\n+  public boolean isPreempted(TaskAttemptId yarnAttemptID) {\n+    return false;\n+  }\n+\n+  @Override\n+  public void reportSuccessfulPreemption(TaskAttemptID taskAttemptID) {\n+    // ignore\n+  }\n+\n+  @Override\n+  public TaskCheckpointID getCheckpointID(TaskID taskId) {\n+    return null;\n+  }\n+\n+  @Override\n+  public void setCheckpointID(TaskID taskId, TaskCheckpointID cid) {\n+    // ignore\n+  }\n+\n+  @Override\n+  public void handleCompletedContainer(TaskAttemptId attemptID) {\n+    // ignore\n+  }\n+\n+}"
        },
        {
            "sha": "0c020aca22b9dd52254791152f7eeafe85f30568",
            "filename": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/preemption/NoopAMPreemptionPolicy.java",
            "status": "added",
            "additions": 72,
            "deletions": 0,
            "changes": 72,
            "blob_url": "https://github.com/apache/hadoop/blob/9ca394d54dd24e67867c845a58150f6b51761512/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-app%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapreduce%2Fv2%2Fapp%2Frm%2Fpreemption%2FNoopAMPreemptionPolicy.java",
            "raw_url": "https://github.com/apache/hadoop/raw/9ca394d54dd24e67867c845a58150f6b51761512/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-app%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapreduce%2Fv2%2Fapp%2Frm%2Fpreemption%2FNoopAMPreemptionPolicy.java",
            "contents_url": "https://api.github.com/repos/apache/hadoop/contents/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-app%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapreduce%2Fv2%2Fapp%2Frm%2Fpreemption%2FNoopAMPreemptionPolicy.java?ref=9ca394d54dd24e67867c845a58150f6b51761512",
            "patch": "@@ -0,0 +1,72 @@\n+/**\n+* Licensed to the Apache Software Foundation (ASF) under one\n+* or more contributor license agreements.  See the NOTICE file\n+* distributed with this work for additional information\n+* regarding copyright ownership.  The ASF licenses this file\n+* to you under the Apache License, Version 2.0 (the\n+* \"License\"); you may not use this file except in compliance\n+* with the License.  You may obtain a copy of the License at\n+*\n+*     http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an \"AS IS\" BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+package org.apache.hadoop.mapreduce.v2.app.rm.preemption;\n+\n+import org.apache.hadoop.mapred.TaskAttemptID;\n+import org.apache.hadoop.mapred.TaskID;\n+import org.apache.hadoop.mapreduce.checkpoint.TaskCheckpointID;\n+import org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId;\n+import org.apache.hadoop.mapreduce.v2.app.AppContext;\n+import org.apache.hadoop.yarn.api.records.PreemptionMessage;\n+\n+/**\n+ * NoOp policy that ignores all the requests for preemption.\n+ */\n+public class NoopAMPreemptionPolicy implements AMPreemptionPolicy {\n+\n+  @Override\n+  public void init(AppContext context){\n+   // do nothing\n+  }\n+\n+  @Override\n+  public void preempt(Context ctxt, PreemptionMessage preemptionRequests) {\n+    // do nothing, ignore all requeusts\n+  }\n+\n+  @Override\n+  public void handleFailedContainer(TaskAttemptId attemptID) {\n+    // do nothing\n+  }\n+\n+  @Override\n+  public boolean isPreempted(TaskAttemptId yarnAttemptID) {\n+    return false;\n+  }\n+\n+  @Override\n+  public void reportSuccessfulPreemption(TaskAttemptID taskAttemptID) {\n+    // ignore\n+  }\n+\n+  @Override\n+  public TaskCheckpointID getCheckpointID(TaskID taskId) {\n+    return null;\n+  }\n+\n+  @Override\n+  public void setCheckpointID(TaskID taskId, TaskCheckpointID cid) {\n+    // ignore\n+  }\n+\n+  @Override\n+  public void handleCompletedContainer(TaskAttemptId attemptID) {\n+    // ignore\n+  }\n+\n+}"
        },
        {
            "sha": "ba8e3d30261072730044a672e09c3f9477012cc3",
            "filename": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/test/java/org/apache/hadoop/mapred/TestTaskAttemptListenerImpl.java",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/apache/hadoop/blob/9ca394d54dd24e67867c845a58150f6b51761512/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-app%2Fsrc%2Ftest%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapred%2FTestTaskAttemptListenerImpl.java",
            "raw_url": "https://github.com/apache/hadoop/raw/9ca394d54dd24e67867c845a58150f6b51761512/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-app%2Fsrc%2Ftest%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapred%2FTestTaskAttemptListenerImpl.java",
            "contents_url": "https://api.github.com/repos/apache/hadoop/contents/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-app%2Fsrc%2Ftest%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapred%2FTestTaskAttemptListenerImpl.java?ref=9ca394d54dd24e67867c845a58150f6b51761512",
            "patch": "@@ -60,7 +60,7 @@ public MockTaskAttemptListenerImpl(AppContext context,\n         JobTokenSecretManager jobTokenSecretManager,\n         RMHeartbeatHandler rmHeartbeatHandler,\n         TaskHeartbeatHandler hbHandler) {\n-      super(context, jobTokenSecretManager, rmHeartbeatHandler);\n+      super(context, jobTokenSecretManager, rmHeartbeatHandler, null);\n       this.taskHeartbeatHandler = hbHandler;\n     }\n     \n@@ -191,7 +191,7 @@ public void testGetMapCompletionEvents() throws IOException {\n         mock(RMHeartbeatHandler.class);\n     final TaskHeartbeatHandler hbHandler = mock(TaskHeartbeatHandler.class);\n     TaskAttemptListenerImpl listener =\n-        new TaskAttemptListenerImpl(appCtx, secret, rmHeartbeatHandler) {\n+        new TaskAttemptListenerImpl(appCtx, secret, rmHeartbeatHandler, null) {\n       @Override\n       protected void registerHeartbeatHandler(Configuration conf) {\n         taskHeartbeatHandler = hbHandler;\n@@ -245,7 +245,7 @@ public void testCommitWindow() throws IOException {\n         mock(RMHeartbeatHandler.class);\n     final TaskHeartbeatHandler hbHandler = mock(TaskHeartbeatHandler.class);\n     TaskAttemptListenerImpl listener =\n-        new TaskAttemptListenerImpl(appCtx, secret, rmHeartbeatHandler) {\n+        new TaskAttemptListenerImpl(appCtx, secret, rmHeartbeatHandler, null) {\n       @Override\n       protected void registerHeartbeatHandler(Configuration conf) {\n         taskHeartbeatHandler = hbHandler;"
        },
        {
            "sha": "7f698c7c0352415f883bfbce737d6ac78a2130f1",
            "filename": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/test/java/org/apache/hadoop/mapreduce/v2/app/MRApp.java",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/apache/hadoop/blob/9ca394d54dd24e67867c845a58150f6b51761512/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-app%2Fsrc%2Ftest%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapreduce%2Fv2%2Fapp%2FMRApp.java",
            "raw_url": "https://github.com/apache/hadoop/raw/9ca394d54dd24e67867c845a58150f6b51761512/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-app%2Fsrc%2Ftest%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapreduce%2Fv2%2Fapp%2FMRApp.java",
            "contents_url": "https://api.github.com/repos/apache/hadoop/contents/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-app%2Fsrc%2Ftest%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapreduce%2Fv2%2Fapp%2FMRApp.java?ref=9ca394d54dd24e67867c845a58150f6b51761512",
            "patch": "@@ -79,6 +79,7 @@\n import org.apache.hadoop.mapreduce.v2.app.rm.ContainerAllocator;\n import org.apache.hadoop.mapreduce.v2.app.rm.ContainerAllocatorEvent;\n import org.apache.hadoop.mapreduce.v2.app.rm.RMHeartbeatHandler;\n+import org.apache.hadoop.mapreduce.v2.app.rm.preemption.AMPreemptionPolicy;\n import org.apache.hadoop.mapreduce.v2.util.MRApps;\n import org.apache.hadoop.metrics2.lib.DefaultMetricsSystem;\n import org.apache.hadoop.net.NetUtils;\n@@ -467,7 +468,8 @@ public void handle(JobFinishEvent event) {\n   }\n \n   @Override\n-  protected TaskAttemptListener createTaskAttemptListener(AppContext context) {\n+  protected TaskAttemptListener createTaskAttemptListener(\n+      AppContext context, AMPreemptionPolicy policy) {\n     return new TaskAttemptListener(){\n       @Override\n       public InetSocketAddress getAddress() {"
        },
        {
            "sha": "baff0c069f494374ef0866d6a7ed956eac7d42dc",
            "filename": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/test/java/org/apache/hadoop/mapreduce/v2/app/MRAppBenchmark.java",
            "status": "modified",
            "additions": 8,
            "deletions": 1,
            "changes": 9,
            "blob_url": "https://github.com/apache/hadoop/blob/9ca394d54dd24e67867c845a58150f6b51761512/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-app%2Fsrc%2Ftest%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapreduce%2Fv2%2Fapp%2FMRAppBenchmark.java",
            "raw_url": "https://github.com/apache/hadoop/raw/9ca394d54dd24e67867c845a58150f6b51761512/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-app%2Fsrc%2Ftest%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapreduce%2Fv2%2Fapp%2FMRAppBenchmark.java",
            "contents_url": "https://api.github.com/repos/apache/hadoop/contents/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-app%2Fsrc%2Ftest%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapreduce%2Fv2%2Fapp%2FMRAppBenchmark.java?ref=9ca394d54dd24e67867c845a58150f6b51761512",
            "patch": "@@ -33,6 +33,8 @@\n import org.apache.hadoop.mapreduce.v2.app.rm.ContainerAllocator;\n import org.apache.hadoop.mapreduce.v2.app.rm.ContainerAllocatorEvent;\n import org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator;\n+import org.apache.hadoop.mapreduce.v2.app.rm.preemption.AMPreemptionPolicy;\n+import org.apache.hadoop.mapreduce.v2.app.rm.preemption.NoopAMPreemptionPolicy;\n import org.apache.hadoop.service.AbstractService;\n import org.apache.hadoop.yarn.api.ApplicationMasterProtocol;\n import org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest;\n@@ -61,6 +63,8 @@ public class MRAppBenchmark {\n \n   /**\n    * Runs memory and time benchmark with Mock MRApp.\n+   * @param app Application to submit\n+   * @throws Exception On application failure\n    */\n   public void run(MRApp app) throws Exception {\n     Logger rootLogger = LogManager.getRootLogger();\n@@ -133,6 +137,7 @@ public void handle(ContainerAllocatorEvent event) {\n       protected void serviceStart() throws Exception {\n         thread = new Thread(new Runnable() {\n           @Override\n+          @SuppressWarnings(\"unchecked\")\n           public void run() {\n             ContainerAllocatorEvent event = null;\n             while (!Thread.currentThread().isInterrupted()) {\n@@ -192,7 +197,9 @@ public void benchmark1() throws Exception {\n       @Override\n       protected ContainerAllocator createContainerAllocator(\n           ClientService clientService, AppContext context) {\n-        return new RMContainerAllocator(clientService, context) {\n+\n+        AMPreemptionPolicy policy = new NoopAMPreemptionPolicy();\n+        return new RMContainerAllocator(clientService, context, policy) {\n           @Override\n           protected ApplicationMasterProtocol createSchedulerProxy() {\n             return new ApplicationMasterProtocol() {"
        },
        {
            "sha": "0fabb207f27e5f78d8c3ba85be908900b7145f6b",
            "filename": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/test/java/org/apache/hadoop/mapreduce/v2/app/TestFail.java",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/apache/hadoop/blob/9ca394d54dd24e67867c845a58150f6b51761512/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-app%2Fsrc%2Ftest%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapreduce%2Fv2%2Fapp%2FTestFail.java",
            "raw_url": "https://github.com/apache/hadoop/raw/9ca394d54dd24e67867c845a58150f6b51761512/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-app%2Fsrc%2Ftest%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapreduce%2Fv2%2Fapp%2FTestFail.java",
            "contents_url": "https://api.github.com/repos/apache/hadoop/contents/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-app%2Fsrc%2Ftest%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapreduce%2Fv2%2Fapp%2FTestFail.java?ref=9ca394d54dd24e67867c845a58150f6b51761512",
            "patch": "@@ -43,6 +43,7 @@\n import org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncher;\n import org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherEvent;\n import org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl;\n+import org.apache.hadoop.mapreduce.v2.app.rm.preemption.AMPreemptionPolicy;\n import org.apache.hadoop.net.NetUtils;\n import org.apache.hadoop.yarn.api.ContainerManagementProtocol;\n import org.apache.hadoop.yarn.api.records.ContainerId;\n@@ -247,13 +248,14 @@ static class TimeOutTaskMRApp extends MRApp {\n       super(maps, reduces, false, \"TimeOutTaskMRApp\", true);\n     }\n     @Override\n-    protected TaskAttemptListener createTaskAttemptListener(AppContext context) {\n+    protected TaskAttemptListener createTaskAttemptListener(\n+        AppContext context, AMPreemptionPolicy policy) {\n       //This will create the TaskAttemptListener with TaskHeartbeatHandler\n       //RPC servers are not started\n       //task time out is reduced\n       //when attempt times out, heartbeat handler will send the lost event\n       //leading to Attempt failure\n-      return new TaskAttemptListenerImpl(getContext(), null, null) {\n+      return new TaskAttemptListenerImpl(getContext(), null, null, policy) {\n         @Override\n         public void startRpcServer(){};\n         @Override"
        },
        {
            "sha": "3a6644e434984def4a139dc9cb04646dfaeee396",
            "filename": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/test/java/org/apache/hadoop/mapreduce/v2/app/TestRMContainerAllocator.java",
            "status": "modified",
            "additions": 11,
            "deletions": 5,
            "changes": 16,
            "blob_url": "https://github.com/apache/hadoop/blob/9ca394d54dd24e67867c845a58150f6b51761512/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-app%2Fsrc%2Ftest%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapreduce%2Fv2%2Fapp%2FTestRMContainerAllocator.java",
            "raw_url": "https://github.com/apache/hadoop/raw/9ca394d54dd24e67867c845a58150f6b51761512/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-app%2Fsrc%2Ftest%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapreduce%2Fv2%2Fapp%2FTestRMContainerAllocator.java",
            "contents_url": "https://api.github.com/repos/apache/hadoop/contents/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-app%2Fsrc%2Ftest%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapreduce%2Fv2%2Fapp%2FTestRMContainerAllocator.java?ref=9ca394d54dd24e67867c845a58150f6b51761512",
            "patch": "@@ -18,6 +18,8 @@\n \n package org.apache.hadoop.mapreduce.v2.app;\n \n+import org.apache.hadoop.mapreduce.v2.app.rm.preemption.NoopAMPreemptionPolicy;\n+\n import static org.mockito.Matchers.anyFloat;\n import static org.mockito.Matchers.anyInt;\n import static org.mockito.Matchers.isA;\n@@ -1428,14 +1430,15 @@ private static ClientService createMockClientService() {\n     // Use this constructor when using a real job.\n     MyContainerAllocator(MyResourceManager rm,\n         ApplicationAttemptId appAttemptId, AppContext context) {\n-      super(createMockClientService(), context);\n+      super(createMockClientService(), context, new NoopAMPreemptionPolicy());\n       this.rm = rm;\n     }\n \n     // Use this constructor when you are using a mocked job.\n     public MyContainerAllocator(MyResourceManager rm, Configuration conf,\n         ApplicationAttemptId appAttemptId, Job job) {\n-      super(createMockClientService(), createAppContext(appAttemptId, job));\n+      super(createMockClientService(), createAppContext(appAttemptId, job),\n+          new NoopAMPreemptionPolicy());\n       this.rm = rm;\n       super.init(conf);\n       super.start();\n@@ -1444,7 +1447,8 @@ public MyContainerAllocator(MyResourceManager rm, Configuration conf,\n     public MyContainerAllocator(MyResourceManager rm, Configuration conf,\n         ApplicationAttemptId appAttemptId, Job job, Clock clock) {\n       super(createMockClientService(),\n-          createAppContext(appAttemptId, job, clock));\n+          createAppContext(appAttemptId, job, clock),\n+          new NoopAMPreemptionPolicy());\n       this.rm = rm;\n       super.init(conf);\n       super.start();\n@@ -1671,7 +1675,8 @@ public void testHeartbeatHandler() throws Exception {\n         ApplicationId.newInstance(1, 1));\n \n     RMContainerAllocator allocator = new RMContainerAllocator(\n-        mock(ClientService.class), appContext) {\n+        mock(ClientService.class), appContext,\n+        new NoopAMPreemptionPolicy()) {\n           @Override\n           protected void register() {\n           }\n@@ -1721,7 +1726,8 @@ public void run() {\n   @Test\n   public void testCompletedContainerEvent() {\n     RMContainerAllocator allocator = new RMContainerAllocator(\n-        mock(ClientService.class), mock(AppContext.class));\n+        mock(ClientService.class), mock(AppContext.class),\n+        new NoopAMPreemptionPolicy());\n     \n     TaskAttemptId attemptId = MRBuilderUtils.newTaskAttemptId(\n         MRBuilderUtils.newTaskId("
        },
        {
            "sha": "f7a87d1ab88536ef281e225d3066cfbd8e8744e4",
            "filename": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/JobCounter.java",
            "status": "modified",
            "additions": 5,
            "deletions": 1,
            "changes": 6,
            "blob_url": "https://github.com/apache/hadoop/blob/9ca394d54dd24e67867c845a58150f6b51761512/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapreduce%2FJobCounter.java",
            "raw_url": "https://github.com/apache/hadoop/raw/9ca394d54dd24e67867c845a58150f6b51761512/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapreduce%2FJobCounter.java",
            "contents_url": "https://api.github.com/repos/apache/hadoop/contents/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapreduce%2FJobCounter.java?ref=9ca394d54dd24e67867c845a58150f6b51761512",
            "patch": "@@ -45,5 +45,9 @@ public enum JobCounter {\n   TOTAL_LAUNCHED_UBERTASKS,\n   NUM_UBER_SUBMAPS,\n   NUM_UBER_SUBREDUCES,\n-  NUM_FAILED_UBERTASKS\n+  NUM_FAILED_UBERTASKS,\n+  TASKS_REQ_PREEMPT,\n+  CHECKPOINTS,\n+  CHECKPOINT_BYTES,\n+  CHECKPOINT_TIME\n }"
        },
        {
            "sha": "e696b865533cf7f5e7d8f6b57f4ecf7e55bd5b5b",
            "filename": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/MRJobConfig.java",
            "status": "modified",
            "additions": 10,
            "deletions": 1,
            "changes": 11,
            "blob_url": "https://github.com/apache/hadoop/blob/9ca394d54dd24e67867c845a58150f6b51761512/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapreduce%2FMRJobConfig.java",
            "raw_url": "https://github.com/apache/hadoop/raw/9ca394d54dd24e67867c845a58150f6b51761512/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapreduce%2FMRJobConfig.java",
            "contents_url": "https://api.github.com/repos/apache/hadoop/contents/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapreduce%2FMRJobConfig.java?ref=9ca394d54dd24e67867c845a58150f6b51761512",
            "patch": "@@ -459,7 +459,13 @@ public interface MRJobConfig {\n   public static final String MR_AM_JOB_REDUCE_PREEMPTION_LIMIT = \n     MR_AM_PREFIX  + \"job.reduce.preemption.limit\";\n   public static final float DEFAULT_MR_AM_JOB_REDUCE_PREEMPTION_LIMIT = 0.5f;\n-  \n+\n+  /**\n+   * Policy class encoding responses to preemption requests.\n+   */\n+  public static final String MR_AM_PREEMPTION_POLICY =\n+    MR_AM_PREFIX + \"preemption.policy\";\n+\n   /** AM ACL disabled. **/\n   public static final String JOB_AM_ACCESS_DISABLED = \n     \"mapreduce.job.am-access-disabled\";\n@@ -708,4 +714,7 @@ public interface MRJobConfig {\n   \n   public static final String MR_APPLICATION_TYPE = \"MAPREDUCE\";\n   \n+  public static final String TASK_PREEMPTION =\n+      \"mapreduce.job.preemption\";\n+\n }"
        },
        {
            "sha": "d2ff26d6b4df58752ddc7d87c0a6a85e197c4883",
            "filename": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/checkpoint/EnumCounter.java",
            "status": "added",
            "additions": 26,
            "deletions": 0,
            "changes": 26,
            "blob_url": "https://github.com/apache/hadoop/blob/9ca394d54dd24e67867c845a58150f6b51761512/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapreduce%2Fcheckpoint%2FEnumCounter.java",
            "raw_url": "https://github.com/apache/hadoop/raw/9ca394d54dd24e67867c845a58150f6b51761512/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapreduce%2Fcheckpoint%2FEnumCounter.java",
            "contents_url": "https://api.github.com/repos/apache/hadoop/contents/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapreduce%2Fcheckpoint%2FEnumCounter.java?ref=9ca394d54dd24e67867c845a58150f6b51761512",
            "patch": "@@ -0,0 +1,26 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.mapreduce.checkpoint;\n+\n+public enum EnumCounter {\n+  INPUTKEY,\n+  INPUTVALUE,\n+  OUTPUTRECORDS,\n+  CHECKPOINT_BYTES,\n+  CHECKPOINT_MS\n+}"
        },
        {
            "sha": "102b84f24832044ae048426212edc205919f9a8f",
            "filename": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/checkpoint/TaskCheckpointID.java",
            "status": "added",
            "additions": 126,
            "deletions": 0,
            "changes": 126,
            "blob_url": "https://github.com/apache/hadoop/blob/9ca394d54dd24e67867c845a58150f6b51761512/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapreduce%2Fcheckpoint%2FTaskCheckpointID.java",
            "raw_url": "https://github.com/apache/hadoop/raw/9ca394d54dd24e67867c845a58150f6b51761512/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapreduce%2Fcheckpoint%2FTaskCheckpointID.java",
            "contents_url": "https://api.github.com/repos/apache/hadoop/contents/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-core%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fhadoop%2Fmapreduce%2Fcheckpoint%2FTaskCheckpointID.java?ref=9ca394d54dd24e67867c845a58150f6b51761512",
            "patch": "@@ -0,0 +1,126 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.mapreduce.checkpoint;\n+\n+import java.io.DataInput;\n+import java.io.DataOutput;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.io.WritableUtils;\n+import org.apache.hadoop.mapred.Counters;\n+\n+/**\n+ * Implementation of CheckpointID used in MR. It contains a reference to an\n+ * underlying FileSsytem based checkpoint, and various metadata about the\n+ * cost of checkpoints and other counters. This is sent by the task to the AM\n+ * to be stored and provided to the next execution of the same task.\n+ */\n+public class TaskCheckpointID implements CheckpointID{\n+\n+  FSCheckpointID rawId;\n+  private List<Path> partialOutput;\n+  private Counters counters;\n+\n+  public TaskCheckpointID() {\n+    this.rawId = new FSCheckpointID();\n+    this.partialOutput = new ArrayList<Path>();\n+  }\n+\n+  public TaskCheckpointID(FSCheckpointID rawId, List<Path> partialOutput,\n+          Counters counters) {\n+    this.rawId = rawId;\n+    this.counters = counters;\n+    if(partialOutput == null)\n+      this.partialOutput = new ArrayList<Path>();\n+    else\n+      this.partialOutput = partialOutput;\n+  }\n+\n+  @Override\n+  public void write(DataOutput out) throws IOException {\n+    counters.write(out);\n+    if (partialOutput == null) {\n+      WritableUtils.writeVLong(out, 0L);\n+    } else {\n+      WritableUtils.writeVLong(out, partialOutput.size());\n+      for(Path p:partialOutput){\n+        Text.writeString(out, p.toString());\n+      }\n+    }\n+    rawId.write(out);\n+  }\n+\n+  @Override\n+  public void readFields(DataInput in) throws IOException {\n+    partialOutput.clear();\n+    counters.readFields(in);\n+    long numPout = WritableUtils.readVLong(in);\n+    for(int i=0;i<numPout;i++)\n+      partialOutput.add(new Path(Text.readString(in)));\n+    rawId.readFields(in);\n+  }\n+\n+  @Override\n+  public boolean equals(Object other){\n+    if (other instanceof TaskCheckpointID){\n+      return this.rawId.equals(((TaskCheckpointID)other).rawId) &&\n+             this.counters.equals(((TaskCheckpointID) other).counters) &&\n+             this.partialOutput.containsAll(((TaskCheckpointID) other).partialOutput) &&\n+             ((TaskCheckpointID) other).partialOutput.containsAll(this.partialOutput);\n+    } else {\n+      return false;\n+    }\n+  }\n+\n+  @Override\n+  public int hashCode() {\n+    return rawId.hashCode();\n+  }\n+\n+  /**\n+   * @return the size of the checkpoint in bytes\n+   */\n+  public long getCheckpointBytes() {\n+    return counters.findCounter(EnumCounter.CHECKPOINT_BYTES).getValue();\n+  }\n+\n+  /**\n+   * @return how long it took to take this checkpoint\n+   */\n+  public long getCheckpointTime() {\n+    return counters.findCounter(EnumCounter.CHECKPOINT_MS).getValue();\n+  }\n+\n+  public String toString(){\n+    return rawId.toString() + \" counters:\" + counters;\n+\n+  }\n+\n+  public List<Path> getPartialCommittedOutput() {\n+    return partialOutput;\n+  }\n+\n+  public Counters getCounters() {\n+    return counters;\n+  }\n+\n+}"
        },
        {
            "sha": "42539a097b221135a5fa52775af3f2f0ec82fc9e",
            "filename": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/resources/org/apache/hadoop/mapreduce/JobCounter.properties",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/apache/hadoop/blob/9ca394d54dd24e67867c845a58150f6b51761512/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-core%2Fsrc%2Fmain%2Fresources%2Forg%2Fapache%2Fhadoop%2Fmapreduce%2FJobCounter.properties",
            "raw_url": "https://github.com/apache/hadoop/raw/9ca394d54dd24e67867c845a58150f6b51761512/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-core%2Fsrc%2Fmain%2Fresources%2Forg%2Fapache%2Fhadoop%2Fmapreduce%2FJobCounter.properties",
            "contents_url": "https://api.github.com/repos/apache/hadoop/contents/hadoop-mapreduce-project%2Fhadoop-mapreduce-client%2Fhadoop-mapreduce-client-core%2Fsrc%2Fmain%2Fresources%2Forg%2Fapache%2Fhadoop%2Fmapreduce%2FJobCounter.properties?ref=9ca394d54dd24e67867c845a58150f6b51761512",
            "patch": "@@ -27,3 +27,7 @@ SLOTS_MILLIS_MAPS.name=            Total time spent by all maps in occupied slot\n SLOTS_MILLIS_REDUCES.name=         Total time spent by all reduces in occupied slots (ms)\n FALLOW_SLOTS_MILLIS_MAPS.name=     Total time spent by all maps waiting after reserving slots (ms)\n FALLOW_SLOTS_MILLIS_REDUCES.name=  Total time spent by all reduces waiting after reserving slots (ms)\n+TASKS_REQ_PREEMPT.name=            Tasks that have been asked to preempt\n+CHECKPOINTS.name=                  Number of checkpoints reported\n+CHECKPOINT_BYTES.name=             Total amount of bytes in checkpoints\n+CHECKPOINT_TIME.name=              Total time spent checkpointing (ms)\n\\ No newline at end of file"
        }
    ]
}